{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d43aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.configuration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0363e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"ordinal_vars_test\"      ## <--- set experiment name\n",
    "LOG_DIR=\"/home/bule/TramDag/dev_experiment_logs\"  ## <--- set log directory\n",
    "EXPERIMENT_DIR = os.path.join(LOG_DIR, experiment_name)\n",
    "CONF_DICT_PATH = os.path.join(EXPERIMENT_DIR, f\"configuration.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e17cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new configuration file at /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/configuration.json\n"
     ]
    }
   ],
   "source": [
    "setup_configuration(experiment_name,EXPERIMENT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06eb83b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable 'x1' is modeled as a continuous variable. for target and predictor.\n",
      "Variable 'x2' is modeled as a continuous variable. for target and predictor.\n",
      "Variable 'x3' is modeled as a continuous variable. for target and predictor.\n",
      "Variable 'x4' is modeled as a continuous variable. for target and predictor.\n",
      "Variable 't1' is modeled as an ordinal   variable. As PREDICTOR: OneHot and TARGET: OneHot.\n",
      "Variable 't2' is modeled as an ordinal   variable. As PREDICTOR: OneHot and TARGET: OneHot.\n",
      "Variable 'x5' is modeled as a continuous variable. for target and predictor.\n",
      "Variable 'y' is modeled as a continuous variable. for target and predictor.\n",
      "Configuration updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# here you need to specify which varibles are in the graph and what type they are (continous or ordinal) for the model builder \n",
    "data_type= {'x1':'continous',\n",
    "            'x2':'continous',\n",
    "            'x3':'continous',\n",
    "            'x4':'continous',\n",
    "            't1':'ordinal_Xn_Yo',\n",
    "            't2':'ordinal_Xn_Yo',\n",
    "            'x5':'continous',\n",
    "            'y':'continous',\n",
    "} \n",
    "\n",
    "write_data_type_to_configuration(data_type, CONF_DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9aa094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matrix found. Please fill out the DAG and click 'Generate'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a675f214854089a4a60b0ccfe11832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=\"Fill in the adjacency matrix (upper triangle only). Use 'ls', 'cs', etc. row:FROM …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_adj_matrix(CONF_DICT_PATH,seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee619cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************\n",
      " Model has Complex intercepts and Complex shifts, please add your Model to the modelzoo \n",
      "*************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f22a9188b04158963a3778eed17b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Edit only the existing model names (non-zero entries).'), GridBox(children=(Label(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_nn_names_matrix(CONF_DICT_PATH, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05947750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2         x3         x4  t1  t2        x5         y\n",
      "0  3.871036  0.722194   1.769079   7.942091   0   0  4.028598 -4.198753\n",
      "1 -4.767804 -3.015394 -12.782749  -1.878498   1   1 -3.802016  9.414157\n",
      "2  5.346699 -5.625096   7.125455  11.368677   1   1  1.743704  6.058449\n",
      "3  5.087093 -7.688708   4.610315   0.677007   0   0 -2.772068 -6.691281\n",
      "4 -4.538803 -2.574087  -9.519076  -3.778644   1   1 -2.202291  8.141716\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      1000 non-null   float64\n",
      " 1   x2      1000 non-null   float64\n",
      " 2   x3      1000 non-null   float64\n",
      " 3   x4      1000 non-null   float64\n",
      " 4   t1      1000 non-null   int64  \n",
      " 5   t2      1000 non-null   int64  \n",
      " 6   x5      1000 non-null   float64\n",
      " 7   y       1000 non-null   float64\n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 62.6 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "from scipy.special import logit\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    make_blobs(n_samples=1000, centers=8, n_features=8, random_state=13)[0],\n",
    "    columns=['x1','x2','x3','x4','t1','t2','x5','y']\n",
    ")\n",
    "\n",
    "\n",
    "df['t1'] = (df['t1'] > df['t1'].median()).astype(int)\n",
    "df['t2']=df['t1'].copy()\n",
    "print(df.head())\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881ab0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47fbdde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] levels are missing for some ordinal variables in configuration dict. THIS will FAIL in model training later!\n",
      " Please provide levels manually to config and reload or compute levels from data using the method compute_levels().\n",
      " e.g. cfg.compute_levels(train_df) # computes levels from training data and writes to cfg\n"
     ]
    }
   ],
   "source": [
    "from utils.tramdag import TramDagConfig , TramDagModel\n",
    "\n",
    "cfg = TramDagConfig.load(\"/home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/configuration.json\")\n",
    "cfg.compute_levels(train_df)\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d00d802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] TramDagModel using device: cpu\n",
      "\n",
      "[INFO] Building model for node 'x1' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu', 'initial_data':            x1        x2         x3         x4  t1  t2        x5         y\n",
      "29   3.778917  4.714700  -9.851478  -4.456896   0   0 -2.687294  3.081479\n",
      "535  3.889792 -5.370922   6.044058  10.270231   1   1  2.924395  4.847949\n",
      "695  6.206760 -8.519790   3.775468  -0.589031   0   0 -5.405793 -7.208941\n",
      "557  9.225430  3.118023  -2.340624   1.365715   1   1  5.754246 -0.620253\n",
      "836 -5.234281 -1.144617 -10.320686  -2.702879   1   1 -2.577204  7.960361\n",
      "..        ...       ...        ...        ...  ..  ..       ...       ...\n",
      "106  6.316279 -5.501693   6.777211   8.925328   1   1  3.449907  5.767779\n",
      "270 -6.629046 -3.360969  -9.827372  -3.679498   1   1 -3.676727  7.263038\n",
      "860 -3.455477  5.100309   7.269814  -5.309903   1   1 -3.981180  1.707555\n",
      "435  4.814736 -8.762771   4.717201   4.009265   0   0 -6.227229 -6.199344\n",
      "102  9.780635  3.814419  -3.598695   0.416361   1   1  5.928739 -2.306723\n",
      "\n",
      "[800 rows x 8 columns]}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x2' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu', 'initial_data':            x1        x2         x3         x4  t1  t2        x5         y\n",
      "29   3.778917  4.714700  -9.851478  -4.456896   0   0 -2.687294  3.081479\n",
      "535  3.889792 -5.370922   6.044058  10.270231   1   1  2.924395  4.847949\n",
      "695  6.206760 -8.519790   3.775468  -0.589031   0   0 -5.405793 -7.208941\n",
      "557  9.225430  3.118023  -2.340624   1.365715   1   1  5.754246 -0.620253\n",
      "836 -5.234281 -1.144617 -10.320686  -2.702879   1   1 -2.577204  7.960361\n",
      "..        ...       ...        ...        ...  ..  ..       ...       ...\n",
      "106  6.316279 -5.501693   6.777211   8.925328   1   1  3.449907  5.767779\n",
      "270 -6.629046 -3.360969  -9.827372  -3.679498   1   1 -3.676727  7.263038\n",
      "860 -3.455477  5.100309   7.269814  -5.309903   1   1 -3.981180  1.707555\n",
      "435  4.814736 -8.762771   4.717201   4.009265   0   0 -6.227229 -6.199344\n",
      "102  9.780635  3.814419  -3.598695   0.416361   1   1  5.928739 -2.306723\n",
      "\n",
      "[800 rows x 8 columns]}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x3' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu', 'initial_data':            x1        x2         x3         x4  t1  t2        x5         y\n",
      "29   3.778917  4.714700  -9.851478  -4.456896   0   0 -2.687294  3.081479\n",
      "535  3.889792 -5.370922   6.044058  10.270231   1   1  2.924395  4.847949\n",
      "695  6.206760 -8.519790   3.775468  -0.589031   0   0 -5.405793 -7.208941\n",
      "557  9.225430  3.118023  -2.340624   1.365715   1   1  5.754246 -0.620253\n",
      "836 -5.234281 -1.144617 -10.320686  -2.702879   1   1 -2.577204  7.960361\n",
      "..        ...       ...        ...        ...  ..  ..       ...       ...\n",
      "106  6.316279 -5.501693   6.777211   8.925328   1   1  3.449907  5.767779\n",
      "270 -6.629046 -3.360969  -9.827372  -3.679498   1   1 -3.676727  7.263038\n",
      "860 -3.455477  5.100309   7.269814  -5.309903   1   1 -3.981180  1.707555\n",
      "435  4.814736 -8.762771   4.717201   4.009265   0   0 -6.227229 -6.199344\n",
      "102  9.780635  3.814419  -3.598695   0.416361   1   1  5.928739 -2.306723\n",
      "\n",
      "[800 rows x 8 columns]}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x4' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu', 'initial_data':            x1        x2         x3         x4  t1  t2        x5         y\n",
      "29   3.778917  4.714700  -9.851478  -4.456896   0   0 -2.687294  3.081479\n",
      "535  3.889792 -5.370922   6.044058  10.270231   1   1  2.924395  4.847949\n",
      "695  6.206760 -8.519790   3.775468  -0.589031   0   0 -5.405793 -7.208941\n",
      "557  9.225430  3.118023  -2.340624   1.365715   1   1  5.754246 -0.620253\n",
      "836 -5.234281 -1.144617 -10.320686  -2.702879   1   1 -2.577204  7.960361\n",
      "..        ...       ...        ...        ...  ..  ..       ...       ...\n",
      "106  6.316279 -5.501693   6.777211   8.925328   1   1  3.449907  5.767779\n",
      "270 -6.629046 -3.360969  -9.827372  -3.679498   1   1 -3.676727  7.263038\n",
      "860 -3.455477  5.100309   7.269814  -5.309903   1   1 -3.981180  1.707555\n",
      "435  4.814736 -8.762771   4.717201   4.009265   0   0 -6.227229 -6.199344\n",
      "102  9.780635  3.814419  -3.598695   0.416361   1   1  5.928739 -2.306723\n",
      "\n",
      "[800 rows x 8 columns]}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 't1' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu', 'initial_data':            x1        x2         x3         x4  t1  t2        x5         y\n",
      "29   3.778917  4.714700  -9.851478  -4.456896   0   0 -2.687294  3.081479\n",
      "535  3.889792 -5.370922   6.044058  10.270231   1   1  2.924395  4.847949\n",
      "695  6.206760 -8.519790   3.775468  -0.589031   0   0 -5.405793 -7.208941\n",
      "557  9.225430  3.118023  -2.340624   1.365715   1   1  5.754246 -0.620253\n",
      "836 -5.234281 -1.144617 -10.320686  -2.702879   1   1 -2.577204  7.960361\n",
      "..        ...       ...        ...        ...  ..  ..       ...       ...\n",
      "106  6.316279 -5.501693   6.777211   8.925328   1   1  3.449907  5.767779\n",
      "270 -6.629046 -3.360969  -9.827372  -3.679498   1   1 -3.676727  7.263038\n",
      "860 -3.455477  5.100309   7.269814  -5.309903   1   1 -3.981180  1.707555\n",
      "435  4.814736 -8.762771   4.717201   4.009265   0   0 -6.227229 -6.199344\n",
      "102  9.780635  3.814419  -3.598695   0.416361   1   1  5.928739 -2.306723\n",
      "\n",
      "[800 rows x 8 columns]}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 't2' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu', 'initial_data':            x1        x2         x3         x4  t1  t2        x5         y\n",
      "29   3.778917  4.714700  -9.851478  -4.456896   0   0 -2.687294  3.081479\n",
      "535  3.889792 -5.370922   6.044058  10.270231   1   1  2.924395  4.847949\n",
      "695  6.206760 -8.519790   3.775468  -0.589031   0   0 -5.405793 -7.208941\n",
      "557  9.225430  3.118023  -2.340624   1.365715   1   1  5.754246 -0.620253\n",
      "836 -5.234281 -1.144617 -10.320686  -2.702879   1   1 -2.577204  7.960361\n",
      "..        ...       ...        ...        ...  ..  ..       ...       ...\n",
      "106  6.316279 -5.501693   6.777211   8.925328   1   1  3.449907  5.767779\n",
      "270 -6.629046 -3.360969  -9.827372  -3.679498   1   1 -3.676727  7.263038\n",
      "860 -3.455477  5.100309   7.269814  -5.309903   1   1 -3.981180  1.707555\n",
      "435  4.814736 -8.762771   4.717201   4.009265   0   0 -6.227229 -6.199344\n",
      "102  9.780635  3.814419  -3.598695   0.416361   1   1  5.928739 -2.306723\n",
      "\n",
      "[800 rows x 8 columns]}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x5' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu', 'initial_data':            x1        x2         x3         x4  t1  t2        x5         y\n",
      "29   3.778917  4.714700  -9.851478  -4.456896   0   0 -2.687294  3.081479\n",
      "535  3.889792 -5.370922   6.044058  10.270231   1   1  2.924395  4.847949\n",
      "695  6.206760 -8.519790   3.775468  -0.589031   0   0 -5.405793 -7.208941\n",
      "557  9.225430  3.118023  -2.340624   1.365715   1   1  5.754246 -0.620253\n",
      "836 -5.234281 -1.144617 -10.320686  -2.702879   1   1 -2.577204  7.960361\n",
      "..        ...       ...        ...        ...  ..  ..       ...       ...\n",
      "106  6.316279 -5.501693   6.777211   8.925328   1   1  3.449907  5.767779\n",
      "270 -6.629046 -3.360969  -9.827372  -3.679498   1   1 -3.676727  7.263038\n",
      "860 -3.455477  5.100309   7.269814  -5.309903   1   1 -3.981180  1.707555\n",
      "435  4.814736 -8.762771   4.717201   4.009265   0   0 -6.227229 -6.199344\n",
      "102  9.780635  3.814419  -3.598695   0.416361   1   1  5.928739 -2.306723\n",
      "\n",
      "[800 rows x 8 columns]}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'y' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu', 'initial_data':            x1        x2         x3         x4  t1  t2        x5         y\n",
      "29   3.778917  4.714700  -9.851478  -4.456896   0   0 -2.687294  3.081479\n",
      "535  3.889792 -5.370922   6.044058  10.270231   1   1  2.924395  4.847949\n",
      "695  6.206760 -8.519790   3.775468  -0.589031   0   0 -5.405793 -7.208941\n",
      "557  9.225430  3.118023  -2.340624   1.365715   1   1  5.754246 -0.620253\n",
      "836 -5.234281 -1.144617 -10.320686  -2.702879   1   1 -2.577204  7.960361\n",
      "..        ...       ...        ...        ...  ..  ..       ...       ...\n",
      "106  6.316279 -5.501693   6.777211   8.925328   1   1  3.449907  5.767779\n",
      "270 -6.629046 -3.360969  -9.827372  -3.679498   1   1 -3.676727  7.263038\n",
      "860 -3.455477  5.100309   7.269814  -5.309903   1   1 -3.981180  1.707555\n",
      "435  4.814736 -8.762771   4.717201   4.009265   0   0 -6.227229 -6.199344\n",
      "102  9.780635  3.814419  -3.598695   0.416361   1   1  5.928739 -2.306723\n",
      "\n",
      "[800 rows x 8 columns]}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n"
     ]
    }
   ],
   "source": [
    "td_model = TramDagModel.from_config(cfg, set_initial_weights=False,verbose=True,debug=True,device=device,initial_data = train_df) \n",
    "# 1m52s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12779127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Computing new minmax dict from training data...\n",
      "[INFO] Saved new minmax dict to /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/min_max_scaling.json\n",
      "[INFO] Training 8 nodes (sequential) on cpu\n",
      "\n",
      "[INFO] Training node 'x1' for 30 epochs on cpu (pid=87207)\n",
      "[INFO] No existing model found. Starting fresh...\n",
      "\n",
      "===== Epoch 1/30 =====\n",
      "[INFO] Saved new best model.\n",
      "[INFO] Epoch 1: Train NLL=4.5147 | Val NLL=4.5098 | Time=0.66s\n",
      "\n",
      "[INFO] Training node 'x2' for 30 epochs on cpu (pid=87207)\n",
      "[INFO] No existing model found. Starting fresh...\n",
      "\n",
      "===== Epoch 1/30 =====\n",
      "[INFO] Saved new best model.\n",
      "[INFO] Epoch 1: Train NLL=4.3500 | Val NLL=4.3148 | Time=0.39s\n",
      "\n",
      "[INFO] Training node 'x3' for 30 epochs on cpu (pid=87207)\n",
      "[INFO] No existing model found. Starting fresh...\n",
      "\n",
      "===== Epoch 1/30 =====\n",
      "[INFO] Saved new best model.\n",
      "[INFO] Epoch 1: Train NLL=4.8384 | Val NLL=4.8639 | Time=0.45s\n",
      "\n",
      "[INFO] Training node 'x4' for 30 epochs on cpu (pid=87207)\n",
      "[INFO] No existing model found. Starting fresh...\n",
      "\n",
      "===== Epoch 1/30 =====\n",
      "[INFO] Saved new best model.\n",
      "[INFO] Epoch 1: Train NLL=4.6417 | Val NLL=4.6050 | Time=0.42s\n",
      "\n",
      "[INFO] Training node 't1' for 30 epochs on cpu (pid=87207)\n",
      "[INFO] No existing model found. Starting fresh...\n",
      "\n",
      "===== Epoch 1/30 =====\n",
      "[INFO] Saved new best model.\n",
      "[INFO] Epoch 1: Train NLL=0.7423 | Val NLL=0.7081 | Time=0.41s\n",
      "\n",
      "[INFO] Training node 't2' for 30 epochs on cpu (pid=87207)\n",
      "[INFO] No existing model found. Starting fresh...\n",
      "\n",
      "===== Epoch 1/30 =====\n",
      "[INFO] Saved new best model.\n",
      "[INFO] Epoch 1: Train NLL=0.7816 | Val NLL=0.7351 | Time=0.42s\n",
      "\n",
      "[INFO] Training node 'x5' for 30 epochs on cpu (pid=87207)\n",
      "[INFO] No existing model found. Starting fresh...\n",
      "\n",
      "===== Epoch 1/30 =====\n",
      "[INFO] Saved new best model.\n",
      "[INFO] Epoch 1: Train NLL=4.1556 | Val NLL=4.1517 | Time=0.47s\n",
      "\n",
      "[INFO] Training node 'y' for 30 epochs on cpu (pid=87207)\n",
      "[INFO] No existing model found. Starting fresh...\n",
      "\n",
      "===== Epoch 1/30 =====\n",
      "[INFO] Saved new best model.\n",
      "[INFO] Epoch 1: Train NLL=8.2712 | Val NLL=8.0864 | Time=0.51s\n"
     ]
    }
   ],
   "source": [
    "td_model.fit(train_df, val_df,\n",
    "             epochs=30,batch_size=1_000,\n",
    "             verbose=True,debug=False,\n",
    "             device=device,\n",
    "             num_workers = 8,\n",
    "             persistent_workers = True,\n",
    "             prefetch_factor = 8,\n",
    "             train_mode = \"sequential\")#,\n",
    "\n",
    "#30 eps 1m 49s seq mode from start 1000 bs\n",
    "#30 eps 2m 27s parllel multiprocessing mode from start 1000 bs\n",
    "# 200 eps 9m 30s seq mode from start 1000 bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cabc55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Skipping node 't1' (ordinal targets not yet supported).\n",
      "[INFO] Skipping node 't2' (ordinal targets not yet supported).\n",
      "[INFO] Final latent DataFrame shape: (800, 12)\n"
     ]
    }
   ],
   "source": [
    "latents=td_model.get_latent( train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fab9b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting full DAG sampling with 10000 samples per node.\n",
      "[INFO] Deleting all previously sampled data.\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x1/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x2/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x3/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x4/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/t1/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/t2/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x5/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/y/sampling\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x1 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node x1 from standard logistic distribution\n",
      "[WARNING] target_col 'x1' not in DataFrame columns — is this intended to be used as a Sampler?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chandrupatla root finding: 100%|██████████| 10000/10000 [00:29<00:00, 336.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Completed sampling for node 'x1'\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x2 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node x2 from standard logistic distribution\n",
      "[WARNING] target_col 'x2' not in DataFrame columns — is this intended to be used as a Sampler?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Chandrupatla root finding: 100%|██████████| 10000/10000 [00:30<00:00, 327.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Completed sampling for node 'x2'\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x3 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node x3 from standard logistic distribution\n",
      "[WARNING] target_col 'x3' not in DataFrame columns — is this intended to be used as a Sampler?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Chandrupatla root finding: 100%|██████████| 10000/10000 [00:29<00:00, 336.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Completed sampling for node 'x3'\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x4 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node x4 from standard logistic distribution\n",
      "[WARNING] target_col 'x4' not in DataFrame columns — is this intended to be used as a Sampler?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Chandrupatla root finding: 100%|██████████| 10000/10000 [00:29<00:00, 338.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Completed sampling for node 'x4'\n",
      "\n",
      "----*----------*-------------*--------Sample Node: t1 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node t1 from standard logistic distribution\n",
      "[WARNING] target_col 't1' not in DataFrame columns — is this intended to be used as a Sampler?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Completed sampling for node 't1'\n",
      "\n",
      "----*----------*-------------*--------Sample Node: t2 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node t2 from standard logistic distribution\n",
      "[WARNING] target_col 't2' not in DataFrame columns — is this intended to be used as a Sampler?\n",
      "[INFO] Completed sampling for node 't2'\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x5 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node x5 from standard logistic distribution\n",
      "[WARNING] target_col 'x5' not in DataFrame columns — is this intended to be used as a Sampler?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chandrupatla root finding: 100%|██████████| 10000/10000 [00:29<00:00, 335.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Completed sampling for node 'x5'\n",
      "\n",
      "----*----------*-------------*--------Sample Node: y ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node y from standard logistic distribution\n",
      "[WARNING] target_col 'y' not in DataFrame columns — is this intended to be used as a Sampler?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Ordinal 't1' values [0.0] do not match expected integers [0.0, 1.0] or scaled floats [0.0, 0.5].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m samples, latents \u001b[38;5;241m=\u001b[39m \u001b[43mtd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TramDag/utils/tramdag.py:1149\u001b[0m, in \u001b[0;36mTramDagModel.sample\u001b[0;34m(self, do_interventions, predefined_latent_samples_df, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] sample(): device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;66;03m# ---- perform sampling ----\u001b[39;00m\n\u001b[0;32m-> 1149\u001b[0m sampled_by_node, latents_by_node \u001b[38;5;241m=\u001b[39m \u001b[43msample_full_dag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_interventions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_interventions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber_of_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelete_all_previously_sampled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelete_all_previously_sampled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminmax_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminmax_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled_by_node, latents_by_node\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data_helpers.py:985\u001b[0m, in \u001b[0;36msample_full_dag\u001b[0;34m(configuration_dict, EXPERIMENT_DIR, device, do_interventions, predefined_latent_samples_df, number_of_samples, batch_size, delete_all_previously_sampled, verbose, debug, minmax_dict)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;66;03m# isntead of sample loader use Generic Dataset but the df is just to sampled data from befor -> create df for each node\u001b[39;00m\n\u001b[1;32m    983\u001b[0m sampled_df\u001b[38;5;241m=\u001b[39mcreate_df_from_sampled(node, target_nodes_dict, number_of_samples, EXPERIMENT_DIR)\n\u001b[0;32m--> 985\u001b[0m sample_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mGenericDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_nodes_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mreturn_intercept_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mreturn_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m sample_loader \u001b[38;5;241m=\u001b[39m DataLoader(sample_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m###*************************************************** Continous Modelled Outcome ************************************************\u001b[39;00m\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data.py:157\u001b[0m, in \u001b[0;36mGenericDataset.__init__\u001b[0;34m(self, df, target_col, target_nodes, transform, return_intercept_shift, return_y, debug, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# checks\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_multiclass_predictors_of_df()\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_ordinal_levels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# precompute tensors\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precompute_all()\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data.py:483\u001b[0m, in \u001b[0;36mGenericDataset._check_ordinal_levels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrdinal \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m values \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muniq\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m do not match expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintegers \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_int\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or scaled floats \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_scaled\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         )\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] _check_ordinal_levels: checked ordinal levels passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Ordinal 't1' values [0.0] do not match expected integers [0.0, 1.0] or scaled floats [0.0, 0.5]."
     ]
    }
   ],
   "source": [
    "samples, latents = td_model.sample(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting full DAG sampling with 10000 samples per node.\n",
      "[INFO] Using predefined latents samples from dataframe -> therefore n_samples is set to the number of rows in the dataframe: 800\n",
      "[INFO] Deleting all previously sampled data.\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x1/sampling\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x2/sampling\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x3/sampling\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x4/sampling\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/t1/sampling\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/t2/sampling\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/x5/sampling\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/ordinal_vars_test/y/sampling\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x1 ------------*-----------------*-------------------*--\n",
      "[INFO] Using predefined latents samples for node x1 from dataframe column: x1_U\n",
      "[WARNING] target_col 'x1' not in DataFrame columns — is this intended to be used as a Sampler?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chandrupatla root finding:  27%|██▋       | 2660/10000 [00:07<00:21, 336.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m samples, latents \u001b[38;5;241m=\u001b[39m \u001b[43mtd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TramDag/utils/tramdag.py:1149\u001b[0m, in \u001b[0;36mTramDagModel.sample\u001b[0;34m(self, do_interventions, predefined_latent_samples_df, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] sample(): device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;66;03m# ---- perform sampling ----\u001b[39;00m\n\u001b[0;32m-> 1149\u001b[0m sampled_by_node, latents_by_node \u001b[38;5;241m=\u001b[39m \u001b[43msample_full_dag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_interventions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_interventions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber_of_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelete_all_previously_sampled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelete_all_previously_sampled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminmax_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminmax_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled_by_node, latents_by_node\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data_helpers.py:996\u001b[0m, in \u001b[0;36msample_full_dag\u001b[0;34m(configuration_dict, EXPERIMENT_DIR, device, do_interventions, predefined_latent_samples_df, number_of_samples, batch_size, delete_all_previously_sampled, verbose, debug, minmax_dict)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m###*************************************************** Continous Modelled Outcome ************************************************\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_outcome_modelled_continous(node,target_nodes_dict):\n\u001b[0;32m--> 996\u001b[0m     sampled\u001b[38;5;241m=\u001b[39m\u001b[43msample_continous_modelled_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_nodes_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtram_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlatent_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\u001b[43mminmax_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminmax_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m###*************************************************** Ordinal Modelled Outcome ************************************************\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_outcome_modelled_ordinal(node,target_nodes_dict):\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data_helpers.py:632\u001b[0m, in \u001b[0;36msample_continous_modelled_target\u001b[0;34m(node, target_nodes_dict, sample_loader, tram_model, latent_sample, device, debug, minmax_dict)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorized_object_function(\n\u001b[1;32m    623\u001b[0m         thetas_expanded,\n\u001b[1;32m    624\u001b[0m         targets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m         k_max\u001b[38;5;241m=\u001b[39mmin_max[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Root finding\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m sampled \u001b[38;5;241m=\u001b[39m \u001b[43mchandrupatla_root_finder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf_vectorized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-12\u001b[39;49m\n\u001b[1;32m    638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(sampled)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoot finding failed: returned None or contains NaNs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/TramDag/utils/loss_continous.py:399\u001b[0m, in \u001b[0;36mchandrupatla_root_finder\u001b[0;34m(f, low, high, max_iter, tol)\u001b[0m\n\u001b[1;32m    391\u001b[0m fallback \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     (s \u001b[38;5;241m<\u001b[39m torch\u001b[38;5;241m.\u001b[39mminimum(a, b)) \u001b[38;5;241m|\u001b[39m\n\u001b[1;32m    393\u001b[0m     (s \u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mmaximum(a, b)) \u001b[38;5;241m|\u001b[39m\n\u001b[1;32m    394\u001b[0m     (torch\u001b[38;5;241m.\u001b[39mabs(s \u001b[38;5;241m-\u001b[39m b) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(b \u001b[38;5;241m-\u001b[39m c) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m|\u001b[39m\n\u001b[1;32m    395\u001b[0m     (torch\u001b[38;5;241m.\u001b[39mabs(b \u001b[38;5;241m-\u001b[39m c) \u001b[38;5;241m<\u001b[39m tol)\n\u001b[1;32m    396\u001b[0m )\n\u001b[1;32m    397\u001b[0m s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(fallback, s_bisect, s)\n\u001b[0;32m--> 399\u001b[0m fs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m c, fc \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mclone(), fb\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    402\u001b[0m use_lower \u001b[38;5;241m=\u001b[39m (fa \u001b[38;5;241m*\u001b[39m fs \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data_helpers.py:622\u001b[0m, in \u001b[0;36msample_continous_modelled_target.<locals>.f_vectorized\u001b[0;34m(targets)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf_vectorized\u001b[39m(targets):\n\u001b[0;32m--> 622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvectorized_object_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthetas_expanded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshifts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatent_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TramDag/utils/loss_continous.py:418\u001b[0m, in \u001b[0;36mvectorized_object_function\u001b[0;34m(thetas, targets, shifts, latent_sample, k_min, k_max)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvectorized_object_function\u001b[39m( thetas: torch\u001b[38;5;241m.\u001b[39mTensor,targets: torch\u001b[38;5;241m.\u001b[39mTensor, shifts: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    416\u001b[0m                                latent_sample: torch\u001b[38;5;241m.\u001b[39mTensor, k_min: \u001b[38;5;28mfloat\u001b[39m, k_max: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# h(xj)-latent_sample=0 , solve for xj\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh_extrapolated_with_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshifts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_max\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m latent_sample\n",
      "File \u001b[0;32m~/TramDag/utils/loss_continous.py:319\u001b[0m, in \u001b[0;36mh_extrapolated_with_shift\u001b[0;34m(thetas, targets, shifts, k_min, k_max)\u001b[0m\n\u001b[1;32m    317\u001b[0m b0 \u001b[38;5;241m=\u001b[39m h_dag(L_tensor\u001b[38;5;241m.\u001b[39mexpand_as(targets), thetas)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m shifts_exp\n\u001b[1;32m    318\u001b[0m slope0 \u001b[38;5;241m=\u001b[39m h_dag_dash(L_tensor\u001b[38;5;241m.\u001b[39mexpand_as(targets), thetas)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 319\u001b[0m h_left \u001b[38;5;241m=\u001b[39m \u001b[43mslope0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_i_exp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mL_tensor\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b0\n\u001b[1;32m    321\u001b[0m h \u001b[38;5;241m=\u001b[39m h_left\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    322\u001b[0m mask0 \u001b[38;5;241m=\u001b[39m t_i_exp \u001b[38;5;241m<\u001b[39m L_tensor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples, latents = td_model.sample(predefined_latent_samples_df=latents, device='cuda') #BUG fix  for ordinal vars sample loader .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06bfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_model.show_samples_vs_true(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tramdag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
