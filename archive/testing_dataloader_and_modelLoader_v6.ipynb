{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32793ca7",
   "metadata": {},
   "source": [
    "## tesing dataloader V5\n",
    "\n",
    "new ideas with ordinal c and yc \n",
    "has ordinal binary and continous outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5f4e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with GPU support.\n"
     ]
    }
   ],
   "source": [
    "# Load dependencies\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from utils.configuration import *\n",
    "from utils.loss_ordinal import *\n",
    "from utils.tram_model_helpers import *\n",
    "from utils.tram_models import *\n",
    "from utils.tram_data import *\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Train with GPU support.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"No GPU found, train with CPU support.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ada57",
   "metadata": {},
   "source": [
    "adjustet funcitnos for ordinal outcomes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678f4f3",
   "metadata": {},
   "source": [
    "dev ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd61311",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"testing_v6_dataloader\"   ## <--- set experiment name\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "\n",
    "LOG_DIR=\"/home/bule/TramDag/dev_experiment_logs\"\n",
    "EXPERIMENT_DIR = os.path.join(LOG_DIR, experiment_name)\n",
    "DATA_PATH = EXPERIMENT_DIR # <----------- change to different source if needed\n",
    "CONF_DICT_PATH = os.path.join(EXPERIMENT_DIR, f\"configuration.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701c538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datatype= \"ordinal_Xc_Yc\" # as X its continous aswell as Y continous\n",
    "# datatype= \"ordinal_Xc_Yo\"\n",
    "# datatype= \"ordinal_Xn_Yc\"\n",
    "# datatype= \"ordinal_Xn_Yo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81881195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"x1\": np.random.normal(loc=0, scale=1, size=1000),\n",
    "    \"ord_bin1\":  np.random.binomial(1, p=0.4, size=1000),\n",
    "    \"ord_multi\": np.random.choice([0, 1, 2, 3], size=1000, p=[0.2, 0.3, 0.3, 0.2]),\n",
    "    \"ord_bin2\":  np.random.binomial(1, p=0.4, size=1000),\n",
    "})\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "quantiles = train_df.quantile([0.05, 0.95])\n",
    "min_vals = quantiles.loc[0.05]\n",
    "max_vals = quantiles.loc[0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd65ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ord_multi': 'ordinal_Xc_Yc', 'x1': 'continous'}\n",
      "{'ord_multi': 4}\n",
      "-----------------ord_multi-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_input tensor([[1.]])\n",
      "shift_list []\n",
      "torch.Size([1, 1])\n",
      "-----------------x1-------------------\n",
      "int_input tensor([[1.]])\n",
      "shift_list [tensor([[3.]])]\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"ord_multi\": np.random.choice([0, 1, 2, 3], size=1000, p=[0.2, 0.3, 0.3, 0.2]),\n",
    "    \"x1\": np.random.normal(loc=0, scale=1, size=1000),\n",
    "})\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "quantiles = train_df.quantile([0.05, 0.95])\n",
    "min_vals = quantiles.loc[0.05]\n",
    "max_vals = quantiles.loc[0.95]\n",
    "\n",
    "\n",
    "data_type={key:value for key, value in zip(train_df.columns, ['ordinal_Xc_Yc']+['continous'])}\n",
    "print(data_type)\n",
    "configuration_dict=new_conf_dict(experiment_name,EXPERIMENT_DIR,DATA_PATH,LOG_DIR)\n",
    "\n",
    "adj_matrix=np.array([['0', 'ls'],\n",
    "                     ['0', '0']])\n",
    "return_intercept_shift=True\n",
    "\n",
    "nn_names_matrix= create_nn_model_names(adj_matrix,data_type)\n",
    "levels_dict=create_levels_dict(df,data_type)\n",
    "target_nodes=create_node_dict(adj_matrix, nn_names_matrix, data_type, min_vals, max_vals,levels_dict)\n",
    "print(levels_dict)\n",
    "\n",
    "for node in target_nodes:\n",
    "    print(f'-----------------{node}-------------------')\n",
    "    train_loader, _ = get_dataloader(node, target_nodes, train_df, val_df, batch_size=1,return_intercept_shift=return_intercept_shift, verbose=False)\n",
    "    \n",
    "    if return_intercept_shift:\n",
    "        (int_input, shift_list), y =next(iter(train_loader))\n",
    "        print(f'int_input {int_input}')\n",
    "        print(f'shift_list {shift_list}')\n",
    "\n",
    "        print(int_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25610ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ord_multi': 'ordinal_Xc_Yc', 'x1': 'continous'}\n",
      "{'ord_multi': 4}\n",
      "-----------------ord_multi-------------------\n",
      "int_input tensor([[1.]])\n",
      "shift_list []\n",
      "torch.Size([1, 1])\n",
      "-----------------x1-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_input tensor([[1.]])\n",
      "shift_list [tensor([[0.7500]])]\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"ord_multi\": np.random.choice([0, 0.25, 0.5, 0.75], size=1000, p=[0.2, 0.3, 0.3, 0.2]),\n",
    "    \"x1\": np.random.normal(loc=0, scale=1, size=1000),\n",
    "})\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "quantiles = train_df.quantile([0.05, 0.95])\n",
    "min_vals = quantiles.loc[0.05]\n",
    "max_vals = quantiles.loc[0.95]\n",
    "\n",
    "\n",
    "data_type={key:value for key, value in zip(train_df.columns, ['ordinal_Xc_Yc']+['continous'])}\n",
    "print(data_type)\n",
    "configuration_dict=new_conf_dict(experiment_name,EXPERIMENT_DIR,DATA_PATH,LOG_DIR)\n",
    "\n",
    "adj_matrix=np.array([['0', 'ls'],\n",
    "                     ['0', '0']])\n",
    "return_intercept_shift=True\n",
    "\n",
    "nn_names_matrix= create_nn_model_names(adj_matrix,data_type)\n",
    "levels_dict=create_levels_dict(df,data_type)\n",
    "target_nodes=create_node_dict(adj_matrix, nn_names_matrix, data_type, min_vals, max_vals,levels_dict)\n",
    "print(levels_dict)\n",
    "\n",
    "for node in target_nodes:\n",
    "    print(f'-----------------{node}-------------------')\n",
    "    train_loader, _ = get_dataloader(node, target_nodes, train_df, val_df, batch_size=1,return_intercept_shift=return_intercept_shift, verbose=False)\n",
    "    \n",
    "    if return_intercept_shift:\n",
    "        (int_input, shift_list), y =next(iter(train_loader))\n",
    "        print(f'int_input {int_input}')\n",
    "        print(f'shift_list {shift_list}')\n",
    "\n",
    "        print(int_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x1': 'continous', 'ord_bin1': 'ordinal_Xn_Yo', 'ord_multi': 'ordinal_Xn_Yo', 'ord_bin2': 'ordinal_Xn_Yo'}\n",
      "*************\n",
      " Model has Complex intercepts and Complex shifts, please add your Model to the modelzoo \n",
      "*************\n",
      "-----------------x1-------------------\n",
      "int_input tensor([[1.]])\n",
      "shift_list []\n",
      "torch.Size([1, 1])\n",
      "-----------------ord_bin1-------------------\n",
      "int_input tensor([[1.]])\n",
      "shift_list []\n",
      "torch.Size([1, 1])\n",
      "-----------------ord_multi-------------------\n",
      "int_input tensor([[1.]])\n",
      "shift_list [tensor([[-0.8895,  0.0000,  1.0000]])]\n",
      "torch.Size([1, 1])\n",
      "-----------------ord_bin2-------------------\n",
      "int_input tensor([[1.]])\n",
      "shift_list [tensor([[0., 0., 1., 0.]]), tensor([[-1.2370,  0.0000,  1.0000]])]\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# data_type={key:value for key, value in zip(train_df.columns, ['continous']+['ordinal_Xn_Yo']+['ordinal_Xn_Yo']+['ordinal_Xn_Yo'])}\n",
    "# print(data_type)\n",
    "# configuration_dict=new_conf_dict(experiment_name,EXPERIMENT_DIR,DATA_PATH,LOG_DIR)\n",
    "\n",
    "# adj_matrix=np.array([['0', '0', 'cs11', 'cs11'],\n",
    "#                      ['0', '0', 'cs12', 'cs12'],\n",
    "#                      ['0', '0', '0', 'cs'],\n",
    "#                      ['0', '0', '0', '0']])\n",
    "\n",
    "# return_intercept_shift=True\n",
    "\n",
    "# nn_names_matrix= create_nn_model_names(adj_matrix,data_type)\n",
    "# levels_dict=create_levels_dict(df,data_type)\n",
    "# target_nodes=create_node_dict(adj_matrix, nn_names_matrix, data_type, min_vals, max_vals,levels_dict)\n",
    "\n",
    "# for node in target_nodes:\n",
    "#     print(f'-----------------{node}-------------------')\n",
    "#     train_loader, _ = get_dataloader(node, target_nodes, train_df, val_df, batch_size=1,return_intercept_shift=return_intercept_shift, verbose=False)\n",
    "    \n",
    "#     if return_intercept_shift:\n",
    "#         (int_input, shift_list), y =next(iter(train_loader))\n",
    "#         print(f'int_input {int_input}')\n",
    "#         print(f'shift_list {shift_list}')\n",
    "\n",
    "#         print(int_input.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tramdag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
