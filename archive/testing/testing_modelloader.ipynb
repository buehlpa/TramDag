{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5e1a005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with GPU support.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "proj_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if proj_root not in sys.path:\n",
    "    sys.path.insert(0, proj_root)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import logistic\n",
    "from scipy.special import logit\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Train with GPU support.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"No GPU found, train with CPU support.\")\n",
    "\n",
    "\n",
    "# own utils\n",
    "from utils.graph import *\n",
    "from utils.tram_models import *\n",
    "from utils.tram_model_helpers import *\n",
    "from utils.tram_data import *\n",
    "from utils.continous import *\n",
    "from utils.sampling_tram_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10287f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "np.random.seed(seed)\n",
    "\n",
    "TEST_DIR=\"/home/bule/TramDag/testing/model_tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9708c596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      1000 non-null   float64\n",
      " 1   x2      1000 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 15.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def dgp_sklearn(nobs=1000, nvars=7, seed=42):\n",
    "    X, _ = make_blobs(n_samples=nobs, n_features=nvars, centers=1,cluster_std=1.0, random_state=seed)\n",
    "    cols = [f'x{i+1}' for i in range(nvars)]\n",
    "    return pd.DataFrame(X, columns=cols)\n",
    "\n",
    "df=dgp_sklearn(nobs=1000, nvars=2, seed=42)\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "data_type= {'x1':'cont','x2':'cont'} # cont:continous, ord:ordinal, oher:everything else than images\n",
    "\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "quantiles = train_df.quantile([0.05, 0.95])\n",
    "min_vals = quantiles.loc[0.05]\n",
    "max_vals = quantiles.loc[0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee587c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_write_test_dict_to_json(input:dict, test_name,file_path = None):\n",
    "    \"\"\"\n",
    "    input has to bea dictionary with the following structure:\n",
    "                                \"input\":{\n",
    "                                                'x1': {\n",
    "                                                'data_type': 'cont',\n",
    "                                                'node_type': 'source',\n",
    "                                                'parents': [],\n",
    "                                                'parents_datatype': {},\n",
    "                                                'transformation_terms_in_h()': {},\n",
    "                                                'transformation_term_nn_models_in_h()': {}},\n",
    "                                                \n",
    "                                For n nodes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "    \n",
    "    data[test_name]={}\n",
    "    data[test_name].setdefault(\"input\", {})\n",
    "    data[test_name].setdefault(\"output\", {})\n",
    "\n",
    "    \n",
    "    data[test_name][\"input\"] = input\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for node_name in input:\n",
    "        model = get_fully_specified_tram_model(node_name, input, verbose=False).to(device)\n",
    "        data[test_name][\"output\"][node_name] = repr(model)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        print(f\"Updated outputs written to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to JSON file: {e}\")\n",
    "        \n",
    "        \n",
    "def run_model_loader_test(test_name: str, testdict_path: str, device: torch.device = None):\n",
    "    \"\"\"\n",
    "    General test for fully_specified_tram_model loader based on ground-truth JSON.\n",
    "\n",
    "    Args:\n",
    "        test_name: Key in the JSON file identifying the test case.\n",
    "        testdict_path: Path to the JSON file containing input and expected output.\n",
    "        device: Torch device to move models to; defaults to CUDA if available, else CPU.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If any model's repr() does not match the expected output.\n",
    "        ValueError: If the test_name is not found in the JSON file.\n",
    "    \"\"\"\n",
    "    # Load ground-truth data\n",
    "    with open(testdict_path, 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    if test_name not in test_data:\n",
    "        raise ValueError(f\"Test name '{test_name}' not found in {testdict_path}\")\n",
    "    \n",
    "\n",
    "    inputs = test_data[test_name]['input']\n",
    "    expected_outputs = test_data[test_name].get('output', {})\n",
    "\n",
    "    # Determine device\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Iterate and compare\n",
    "    for node_name in inputs:\n",
    "        model = get_fully_specified_tram_model(node_name, inputs, verbose=False).to(device)\n",
    "        actual_repr = repr(model)\n",
    "        expected_repr = expected_outputs.get(node_name)\n",
    "\n",
    "        assert expected_repr is not None, (\n",
    "            f\"No expected output found for node '{node_name}' \"\n",
    "            f\"in '{testdict_path}'.\"\n",
    "        )\n",
    "        assert actual_repr == expected_repr, (\n",
    "            f\"Mismatch for node '{node_name}':\\n\"\n",
    "            f\"  Expected: {expected_repr}\\n\"\n",
    "            f\"  Actual:   {actual_repr}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2827f9",
   "metadata": {},
   "source": [
    "# Testing 2 variables\n",
    "4 tests SI LS, CS and CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ff5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/twovars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "# LS\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1'],\n",
    "        'parents_datatype': {'x1': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'ls'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'LinearShift'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_1\", file_path = os.path.join(TEST_DIR, 'twovars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5724ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/twovars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "# CS\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1'],\n",
    "        'parents_datatype': {'x1': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'ls'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'ComplexShiftDefaultTabular'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_2\",file_path = os.path.join(TEST_DIR, 'twovars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42475056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/twovars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "# CI\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1'],\n",
    "        'parents_datatype': {'x1': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'ci'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'ComplexInterceptDefaultTabular'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_3\",file_path = os.path.join(TEST_DIR, 'twovars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f9d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this tests all the 3 cases for SI LS CS and CI\n",
    "\n",
    "for test in ['test_1', 'test_2', 'test_3']:\n",
    "    run_model_loader_test(test, os.path.join(TEST_DIR, 'twovars_model_loader_test_dict.json'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a7840",
   "metadata": {},
   "source": [
    "# 3vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f10aee70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/threevars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "# TODO here is a bug when 2 linera shifts are used in the same model, e.g. when we have a model like this:\n",
    "\n",
    "#  X3 ~ LS(X1) + LS(X2)\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x3': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1','x2'],\n",
    "        'parents_datatype': {'x1': 'cont','x2': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'ls','x2': 'ls'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'LinearShift','x2': 'LinearShift'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_1\", file_path = os.path.join(TEST_DIR, 'threevars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c6626e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/threevars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "#  X3 ~ CS(X1) + LS(X2)\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x3': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1','x2'],\n",
    "        'parents_datatype': {'x1': 'cont','x2': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'cs','x2': 'ls'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'ComplexShiftDefaultTabular','x2': 'LinearShift'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_2\", file_path = os.path.join(TEST_DIR, 'threevars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7050d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/threevars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "#  X3 ~ CS(X1) + CS(X2)\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x3': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1','x2'],\n",
    "        'parents_datatype': {'x1': 'cont','x2': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'cs','x2': 'cs'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'ComplexShiftDefaultTabular','x2': 'ComplexShiftDefaultTabular'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_3\", file_path = os.path.join(TEST_DIR, 'threevars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6feb5209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/threevars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "#  X3 ~ CS(X1) + CI(X2)\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x3': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1','x2'],\n",
    "        'parents_datatype': {'x1': 'cont','x2': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'cs','x2': 'ci'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'ComplexShiftDefaultTabular','x2': 'ComplexInterceptDefaultTabular'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_4\", file_path = os.path.join(TEST_DIR, 'threevars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8655ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/threevars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "#  X3 ~ CS11(X1) + CS12(X2)\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x3': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1','x2'],\n",
    "        'parents_datatype': {'x1': 'cont','x2': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'cs11','x2': 'cs12'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'ComplexShiftDefaultTabular11','x2': 'ComplexShiftDefaultTabular12'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_5\", file_path = os.path.join(TEST_DIR, 'threevars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6814e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/threevars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "#  X3 ~ CI11(X1) + CI12(X2)\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x3': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1','x2'],\n",
    "        'parents_datatype': {'x1': 'cont','x2': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'ci11','x2': 'ci12'},\n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'ComplexInterceptDefaultTabular11','x2': 'ComplexInterceptDefaultTabular12'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_6\", file_path = os.path.join(TEST_DIR, 'threevars_model_loader_test_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a84be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this tests all the 3 cases for SI LS CS and CI\n",
    "\n",
    "for test in ['test_1', 'test_2', 'test_3', 'test_4', 'test_5', 'test_6']:\n",
    "    run_model_loader_test(test, os.path.join(TEST_DIR, 'threevars_model_loader_test_dict.json'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8946173e",
   "metadata": {},
   "source": [
    "# 10 variables\n",
    "\n",
    "testing cases for multiple groups\n",
    "\n",
    "like ci11 ci12 , cs11 cs12, cs21 cs22, ls , cs , cs31, cs32 , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e6973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outputs written to /home/bule/TramDag/testing/model_tests/tenvars_model_loader_test_dict.json\n"
     ]
    }
   ],
   "source": [
    "#  X10 ~ CI12(X1) + CS12(X2) + LS(X3) + CS11(X4) + CS(X5) + CS22(X6) + CS21(X7) + CS32(X8) + CI11(X9)\n",
    "input={\n",
    "        'x1': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x2': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x3': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x4': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x5': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x6': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x7': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x8': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x9': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'source',\n",
    "        'parents': [],\n",
    "        'parents_datatype': {},\n",
    "        'transformation_terms_in_h()': {},\n",
    "        'transformation_term_nn_models_in_h()': {}},\n",
    "        'x10': {\n",
    "        'data_type': 'cont',\n",
    "        'node_type': 'sink',\n",
    "        'parents': ['x1','x2','x3','x4','x5','x7','x8','x9'],\n",
    "        'parents_datatype': {'x1': 'cont','x2': 'cont','x2': 'cont','x3': 'cont','x4': 'cont','x5': 'cont','x6': 'cont','x7': 'cont','x8': 'cont','x9': 'cont'},\n",
    "        'transformation_terms_in_h()': {'x1': 'ci12',\n",
    "                                        'x2': 'cs12',\n",
    "                                        'x3': 'ls',\n",
    "                                        'x4': 'cs11',\n",
    "                                        'x5': 'cs',\n",
    "                                        'x6': 'cs22',\n",
    "                                        'x7': 'cs21',\n",
    "                                        'x8': 'cs32',\n",
    "                                        'x9': 'ci11'},\n",
    "        \n",
    "        'transformation_term_nn_models_in_h()': {'x1': 'ComplexInterceptDefaultTabular12',\n",
    "                                                 'x2': 'ComplexShiftDefaultTabular12',\n",
    "                                                 'x3': 'LinearShift',\n",
    "                                                 'x4': 'ComplexShiftDefaultTabular11',\n",
    "                                                 'x5': 'ComplexShiftDefaultTabular',\n",
    "                                                 'x6': 'ComplexShiftDefaultTabular22',\n",
    "                                                 'x7': 'ComplexShiftDefaultTabular21',\n",
    "                                                 'x8': 'ComplexShiftDefaultTabular',\n",
    "                                                 'x9': 'ComplexInterceptDefaultTabular11'}}\n",
    "        }\n",
    "\n",
    "load_and_write_test_dict_to_json(input, \"test_1\", file_path = os.path.join(TEST_DIR, 'tenvars_model_loader_test_dict.json'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tramdag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
