{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee803ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplingDataset(Dataset):\n",
    "    def __init__(self, node,EXPERIMENT_DIR,number_of_samples=100,rootfinder='bisection', target_nodes=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            node (str): Name of the target node.\n",
    "            conf_dict (dict): Mapping variable names to their types: \"cont\", \"other\", \"ord\".\n",
    "            transform (callable, optional): Optional transform to apply to image data.\n",
    "        \"\"\"\n",
    "        self.EXPERIMENT_DIR=EXPERIMENT_DIR\n",
    "        self.node = node\n",
    "        self.number_of_samples=number_of_samples\n",
    "        self.target_nodes = target_nodes\n",
    "        self.transform = transform\n",
    "        self.rootfinder=rootfinder\n",
    "        self.predictors = None if target_nodes is None else self._ordered_keys()\n",
    "        self.datatensors = self._get_sampled_parent_tensors()# shape: (num_parents, num_samples, dim)\n",
    "        _,self.transformation_terms_in_h, _ = ordered_parents(self.node, self.target_nodes)\n",
    "\n",
    "    def _get_sampled_parent_tensors(self):\n",
    "        ## loads parent roots if they are available \n",
    "        tensor_list = []\n",
    "        if self.target_nodes is None or self.target_nodes[self.node]['node_type'] == 'source':\n",
    "            tensor_list.append(torch.ones(self.number_of_samples) * 1.0)\n",
    "            return tensor_list \n",
    "        else:        \n",
    "            parents_dataype_dict, _, _ = ordered_parents(self.node, self.target_nodes)\n",
    "        for parent_pair in parents_dataype_dict:\n",
    "            # print(parent_pair)\n",
    "            PARENT_DIR = os.path.join(self.EXPERIMENT_DIR, f'{parent_pair}')\n",
    "            tensor = load_roots(PARENT_DIR,rootfinder=self.rootfinder)  # expected shape: (num_samples, feature_dim) # TODO change the fucnitno name because its not roots its sampled observations or interventional data\n",
    "            tensor_list.append(torch.tensor(tensor))  # ensure tensor type\n",
    "        return tensor_list  # list of tensors, each (num_samples, dim)\n",
    "\n",
    "    def _ordered_keys(self):\n",
    "        parents_dataype_dict, _, _ = ordered_parents(self.node, self.target_nodes)\n",
    "        return list(parents_dataype_dict.keys())\n",
    "\n",
    "    def __len__(self):        \n",
    "        return self.datatensors[0].shape[0]  # assuming same num_samples for all\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_data = []\n",
    "        \n",
    "        if self.target_nodes is None or self.target_nodes[self.node]['node_type'] == 'source':\n",
    "            return (torch.tensor([1.0], dtype=torch.float32),)\n",
    "\n",
    "        if all('i' not in str(value) for value in self.transformation_terms_in_h.values()):\n",
    "            x = torch.tensor(1.0) \n",
    "            x_data.append(x)\n",
    "\n",
    "        for i, var in enumerate(self.predictors):\n",
    "            if self.target_nodes[var]['data_type'] == \"cont\":\n",
    "                val = self.datatensors[i][idx]\n",
    "                x_data.append(val.unsqueeze(0))  # ensure shape (1,)\n",
    "            elif self.target_nodes[var]['data_type'] == \"ord\":\n",
    "                val = self.datatensors[i][idx]\n",
    "                x_data.append(val.unsqueeze(0).long())  # ensure shape (1,) and long\n",
    "            elif self.target_nodes[var]['data_type'] == \"other\":\n",
    "                img_path = self.datatensors[i][idx]\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                x_data.append(image)\n",
    "                \n",
    "                \n",
    "        # fixed shape here : quick and dirty , resolve later\n",
    "        squeezed = []\n",
    "        for t in x_data:\n",
    "            if isinstance(t, torch.Tensor) and t.dim() == 1 and t.shape[0] == 1:\n",
    "                squeezed.append(t.squeeze(0))  # from shape (1,) â†’ shape ()\n",
    "            else:\n",
    "                squeezed.append(t)\n",
    "        return tuple(squeezed)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
