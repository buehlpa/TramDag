{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e076b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from scipy.stats import logistic\n",
    "# from scipy.special import logit\n",
    "\n",
    "import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Train with GPU support.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"No GPU found, train with CPU support.\")\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# own utils\n",
    "from utils.graph import *\n",
    "from utils.tram_models import *\n",
    "from utils.tram_model_helpers import *\n",
    "from utils.tram_data import *\n",
    "from utils.loss_continous import *\n",
    "from utils.sampling_tram_data import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8923b899",
   "metadata": {},
   "source": [
    "# 1. Experiments and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b984f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"ordinal_dev\"   ## <--- set experiment name\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "\n",
    "LOG_DIR=\"/home/bule/TramDag/dev_experiment_logs\"\n",
    "EXPERIMENT_DIR = os.path.join(LOG_DIR, experiment_name)\n",
    "DATA_PATH = EXPERIMENT_DIR # <----------- change to different source if needed\n",
    "CONF_DICT_PATH = os.path.join(EXPERIMENT_DIR, f\"configuration.json\")\n",
    "\n",
    "os.makedirs(EXPERIMENT_DIR,exist_ok=True)\n",
    "# check if configration dict already exists if not create:\n",
    "\n",
    "if os.path.exists(CONF_DICT_PATH):\n",
    "    configuration_dict=load_configuration_dict(CONF_DICT_PATH)\n",
    "    print(f\"Loaded existing configuration from {CONF_DICT_PATH}\")\n",
    "else:\n",
    "    configuration_dict=create_and_write_new_configuration_dict(experiment_name,CONF_DICT_PATH,EXPERIMENT_DIR,DATA_PATH,LOG_DIR)\n",
    "    print(f\"Created new configuration file at {CONF_DICT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76549b97",
   "metadata": {},
   "source": [
    "# 2.  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f916214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dgp(n_obs, doX=[None, None, None], f=lambda x: x, seed=None):\n",
    "    \"\"\"\n",
    "    Modified data-generating process.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_obs : int\n",
    "        Number of observations to generate.\n",
    "    doX : list of length 3\n",
    "        If doX[i] is not None, fixes X_{i+1} to that constant for all draws.\n",
    "    f : callable\n",
    "        A function of X2 used in generating X3 (defaults to identity).\n",
    "    seed : int or None\n",
    "        If provided, sets the NumPy random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns ['x1', 'x2', 'x3'], where x1 and x2 are\n",
    "        binary ordered categoricals, and x3 is continuous.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        print(f\"Setting seed: {seed}\")\n",
    "\n",
    "    # --- 1. Sample binary X1 ---\n",
    "    if doX[0] is None:\n",
    "        x1_num = np.random.binomial(n=1, p=0.9, size=n_obs)\n",
    "    else:\n",
    "        x1_num = np.full(n_obs, doX[0], dtype=int)\n",
    "    x1 = pd.Categorical(x1_num, categories=[0, 1], ordered=True)\n",
    "\n",
    "    # --- 2. Sample binary X2 ---\n",
    "    if doX[1] is None:\n",
    "        x2_num = np.random.binomial(n=1, p=0.45, size=n_obs)\n",
    "    else:\n",
    "        x2_num = np.full(n_obs, doX[1], dtype=int)\n",
    "    x2 = pd.Categorical(x2_num, categories=[0, 1], ordered=True)\n",
    "\n",
    "    # --- 3. Sample continuous X3 ---\n",
    "    if doX[2] is None:\n",
    "        noise = np.random.normal(loc=0.0, scale=1.0, size=n_obs)\n",
    "        x3 = 0 + 0.5 * x1_num + f(x2_num) + noise\n",
    "    else:\n",
    "        x3 = np.full(n_obs, doX[2], dtype=float)\n",
    "\n",
    "    return pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3})\n",
    "\n",
    "\n",
    "\n",
    "df = dgp(n_obs=1_000, seed=42)\n",
    "\n",
    "\n",
    "plt.hist(df['x1'], density=True)\n",
    "plt.xticks([0, 1])\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.title('Relative Frequency Histogram of x3')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(df['x2'], density=True)\n",
    "plt.xticks([0, 1,])\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.title('Relative Frequency Histogram of x3')\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "sns.pairplot(df)\n",
    "\n",
    "EXP_DATA_PATH=os.path.join(DATA_PATH, f\"{experiment_name}.csv\")\n",
    "if not os.path.exists(EXP_DATA_PATH):\n",
    "    df = dgp(n_obs=1_000, seed=42)\n",
    "    df['x1']=df['x1'].astype(int)\n",
    "    df['x2']=df['x2'].astype(int)\n",
    "\n",
    "    print(df.head())\n",
    "    df.to_csv(EXP_DATA_PATH, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(EXP_DATA_PATH)\n",
    "    df['x2']=df['x2'].astype(int)\n",
    "    df['x1']=df['x1'].astype(int)\n",
    "\n",
    "    print(f\"Loaded data from {EXP_DATA_PATH}\")\n",
    "\n",
    "\n",
    "data_type= {'x1':'ord','x2':'ord','x3':'cont'} # cont:continous, ord:ordinal, oher:everything else than images\n",
    "\n",
    "write_data_type_to_configuration(data_type, CONF_DICT_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d527e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5a0fb",
   "metadata": {},
   "source": [
    "## 2.1 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2733e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# 2. Compute quantiles from training data\n",
    "quantiles = train_df.quantile([0.05, 0.95])\n",
    "min_vals = quantiles.loc[0.05]\n",
    "max_vals = quantiles.loc[0.95]\n",
    "\n",
    "# 3. Normalize all sets using training quantiles\n",
    "def normalize_with_quantiles(df, min_vals, max_vals):\n",
    "    return (df - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "# train_df = normalize_with_quantiles(train_df, min_vals, max_vals)\n",
    "# val_df = normalize_with_quantiles(val_df, min_vals, max_vals)\n",
    "# test_df = normalize_with_quantiles(test_df, min_vals, max_vals)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b97f69",
   "metadata": {},
   "source": [
    "# 3. Define graph Structure\n",
    "\n",
    "- define graph and which shift and intercept terms to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcd902",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_adj_matrix(CONF_DICT_PATH,seed=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7328e1",
   "metadata": {},
   "source": [
    "# 4. Configuration for the Models\n",
    "\n",
    "- all SI and LS model are generated outmatically since these are shallow NN's\n",
    "- CI and CS have to be defined by the User and can be Passed for each model, -> generate default networks which are generated automaitcally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314149ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_nn_names_matrix(CONF_DICT_PATH, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_nodes_information_to_configuration_v2(CONF_DICT_PATH, min_vals, max_vals,levels_dict={'x1': 2,'x2': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed791d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericDataset_v3(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        target_col,\n",
    "        target_nodes=None,\n",
    "        parents_dataype_dict=None,\n",
    "        transform=None,\n",
    "        transformation_terms_in_h=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        df: pd.DataFrame\n",
    "        target_col: str\n",
    "        target_nodes: dict mapping each node → metadata (including 'data_type')\n",
    "        parents_dataype_dict: dict var_name → \"cont\"|\"ord\"|\"other\"\n",
    "        transform: torchvision transform for images\n",
    "        transformation_terms_in_h: dict for intercept logic\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.target_col = target_col\n",
    "        self.target_nodes = target_nodes or {}\n",
    "        self.parents_dataype_dict = parents_dataype_dict or {}\n",
    "        self.variables = list(self.parents_dataype_dict.keys())\n",
    "        self.transform = transform\n",
    "        self.transformation_terms_in_h = transformation_terms_in_h or {}\n",
    "                # If we know this target is ordinal, record #classes\n",
    "        if (\n",
    "            self.target_nodes\n",
    "            and self.target_col in self.target_nodes\n",
    "            and self.target_nodes[self.target_col].get('data_type') == \"ord\"\n",
    "        ):\n",
    "            self.target_num_classes = int(self.df[self.target_col].nunique())\n",
    "        else:\n",
    "            self.target_num_classes = None\n",
    "\n",
    "        self._check_binary_values_of_df()\n",
    "        \n",
    "    def _transform_y(self,row):\n",
    "        # handle y\n",
    "        if self.target_num_classes is not None:\n",
    "            # ordinal source → one-hot\n",
    "            raw = row[self.target_col]\n",
    "            y_int = int(raw)\n",
    "            y = F.one_hot(torch.tensor(y_int, dtype=torch.long), num_classes=self.target_num_classes).float()\n",
    "            \n",
    "        else:\n",
    "            # continuous or other\n",
    "            y = torch.tensor(row[self.target_col], dtype=torch.float32)\n",
    "        return y\n",
    "\n",
    "    def _check_binary_values_of_df(self):\n",
    "        for var in self.variables:\n",
    "            dtype = self.parents_dataype_dict[var]\n",
    "            if dtype != \"ord\":\n",
    "                continue\n",
    "\n",
    "            unique_vals = set(self.df[var].dropna().unique())\n",
    "            if len(unique_vals) == 2:\n",
    "                if unique_vals != {0, 1}:\n",
    "                    raise ValueError(\n",
    "                        f\"Variable '{var}' is marked as ordinal with 2 classes, \"\n",
    "                        f\"but values are {unique_vals}. Please provide binary ordinal variables as 0 and 1.\"\n",
    "                    )\n",
    "            elif len(unique_vals) < 2:\n",
    "                raise ValueError(\n",
    "                    f\"Variable '{var}' has fewer than 2 unique values: {unique_vals}. \"\n",
    "                    \"Binary ordinal variables must have exactly two distinct values: 0 and 1.\"\n",
    "                )\n",
    "                        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        x_data = []\n",
    "\n",
    "        # --- SOURCE NODE: no parents → x = [1.0] ---\n",
    "        if not self.parents_dataype_dict:\n",
    "            x_data = [torch.tensor(1.0)]\n",
    "            y=self._transform_y(row)\n",
    "            return tuple(x_data), y\n",
    "\n",
    "        # --- INTERCEPT if needed ---\n",
    "        if all('i' not in str(v) for v in self.transformation_terms_in_h.values()):\n",
    "            x_data.append(torch.tensor(1.0))\n",
    "\n",
    "        # --- BUILD FEATURES ---\n",
    "        for var in self.variables:\n",
    "            dtype = self.parents_dataype_dict[var]\n",
    "            ## Continous  feature\n",
    "            if dtype == \"cont\":\n",
    "                x_data.append(torch.tensor(row[var], dtype=torch.float32))\n",
    "                \n",
    "            ## Ordinal feature , if it has more thatn 2 classes it uses onehotencodig, if binary use just 0 and 1\n",
    "            elif dtype == \"ord\":\n",
    "                x_ord = int(row[var])\n",
    "                var_num_classes=int(self.df[var].nunique())\n",
    "                if var_num_classes>2:\n",
    "                    x_ord_onehot = F.one_hot(torch.tensor(x_ord, dtype=torch.long),num_classes=var_num_classes).float()\n",
    "                    x_data.append(x_ord_onehot)\n",
    "                \n",
    "                else:\n",
    "                    x_data.append(torch.tensor(x_ord, dtype=torch.long))\n",
    "                \n",
    "            else:  # \"other\"\n",
    "                img = Image.open(row[var]).convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                x_data.append(img)\n",
    "\n",
    "        # --- BUILD TARGET ---\n",
    "        y=self._transform_y(row)\n",
    "            \n",
    "            \n",
    "        return tuple(x_data), y\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader_v3(node, target_nodes, train_df, val_df, batch_size=32, verbose=False):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    if target_nodes[node]['node_type'] == 'source':\n",
    "        if verbose:\n",
    "            print('Source node → features are just a constant 1.')\n",
    "        train_ds = GenericDataset_v3(train_df,target_col=node,target_nodes=target_nodes,parents_dataype_dict=None,transform=transform)\n",
    "        val_ds = GenericDataset_v3(val_df,target_col=node,target_nodes=target_nodes,parents_dataype_dict=None,transform=transform)\n",
    "        \n",
    "    else:\n",
    "        parents_dataype_dict, transformation_terms_in_h, _ = ordered_parents(node, target_nodes)\n",
    "        if verbose:\n",
    "            print(f\"Parents dtype: {parents_dataype_dict}\")\n",
    "        train_ds = GenericDataset_v3(train_df,target_col=node,target_nodes=target_nodes,parents_dataype_dict=parents_dataype_dict,transform=transform,transformation_terms_in_h=transformation_terms_in_h)\n",
    "        val_ds = GenericDataset_v3(val_df,target_col=node,target_nodes=target_nodes,parents_dataype_dict=parents_dataype_dict,transform=transform,transformation_terms_in_h=transformation_terms_in_h)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_TRAINING=True\n",
    "train_list=['x1','x2','x3']#['x2']#'x1','x2']#,'x3']#['x1']#['x1','x2','x3']#,#,['x1','x2','x3'] # <-  set the nodes which have to be trained , useful if further training is required else lsit all vars\n",
    "\n",
    "batch_size = 1#4112\n",
    "epochs = 10# <- if you want a higher numbe rof epochs, set the number higher and it loads the old model and starts from there\n",
    "learning_rate=0.01\n",
    "use_scheduler =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54370430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each NODE \n",
    "configuration_dict = load_configuration_dict(CONF_DICT_PATH)\n",
    "target_nodes = configuration_dict['nodes']\n",
    "\n",
    "\n",
    "for node in target_nodes:\n",
    "    \n",
    "    print(node)\n",
    "    \n",
    "\n",
    "    ########################## 3. Create Dataloaders ########################\n",
    "    train_loader, val_loader = get_dataloader_v3(node, target_nodes, train_df, val_df, batch_size=batch_size, verbose=True)\n",
    "    print(next(iter(train_loader)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_TRAINING=True\n",
    "train_list=['x1','x2','x3']#['x2']#'x1','x2']#,'x3']#['x1']#['x1','x2','x3']#,#,['x1','x2','x3'] # <-  set the nodes which have to be trained , useful if further training is required else lsit all vars\n",
    "\n",
    "batch_size = 512#4112\n",
    "epochs = 10# <- if you want a higher numbe rof epochs, set the number higher and it loads the old model and starts from there\n",
    "learning_rate=0.01\n",
    "use_scheduler =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each NODE \n",
    "configuration_dict = load_configuration_dict(CONF_DICT_PATH)\n",
    "target_nodes = configuration_dict['nodes']\n",
    "\n",
    "\n",
    "for node in target_nodes:\n",
    "    \n",
    "    print(f'\\n----*----------*-------------*--------------- Node: {node} ------------*-----------------*-------------------*--')\n",
    "    ########################## 0. Skip nodes ###############################\n",
    "    if node not in train_list:# Skip if node is not in train_list\n",
    "        print(f\"Skipping node {node} as it's not in the training list.\")\n",
    "        continue\n",
    "    if (target_nodes[node]['node_type'] == 'source') and (target_nodes[node]['node_type'] == 'other'):# Skip unsupported types\n",
    "        print(f\"Node type : other , is not supported yet\")\n",
    "        continue\n",
    "\n",
    "    ########################## 1. Setup Paths ###############################\n",
    "    NODE_DIR = os.path.join(EXPERIMENT_DIR, f'{node}')\n",
    "    os.makedirs(NODE_DIR, exist_ok=True)\n",
    "    \n",
    "    # Check if training is complete\n",
    "    if not check_if_training_complete(node, NODE_DIR, epochs):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    ########################## 2. Create Model ##############################\n",
    "    tram_model = get_fully_specified_tram_model_v2(node, target_nodes, verbose=True).to(device)\n",
    "\n",
    "    \n",
    "    ########################## 3. Create Dataloaders ########################\n",
    "    train_loader, val_loader = get_dataloader_v2(node, target_nodes, train_df, val_df, batch_size=batch_size, verbose=True)\n",
    "\n",
    "    ########################## 5. Optimizer & Scheduler ######################.\n",
    "    \n",
    "    optimizer =torch.optim.Adam(tram_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    ########################## 7. Training Loop ##############################\n",
    "    \n",
    "    train_val_loop_v3(\n",
    "                   node,\n",
    "                   target_nodes,\n",
    "                   NODE_DIR,\n",
    "                   tram_model,\n",
    "                   train_loader,\n",
    "                   val_loader,\n",
    "                   epochs,\n",
    "                   optimizer,\n",
    "                   use_scheduler,\n",
    "                   scheduler,\n",
    "                   save_linear_shifts=False,\n",
    "                   verbose=1,\n",
    "                   device=device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13c140",
   "metadata": {},
   "source": [
    "# 6 Inspect Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4e2c7",
   "metadata": {},
   "source": [
    "## 6.1 Loss vs epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_training_history(target_nodes,EXPERIMENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b5922",
   "metadata": {},
   "source": [
    "## 6.2 inspect transformation function for source nodes h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_hdag_for_source_nodes_v2(target_nodes,EXPERIMENT_DIR,device,xmin_plot=0,xmax_plot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a058e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.loss_ordinal import transform_intercepts_ordinal\n",
    "\n",
    "def show_hdag_for_single_source_node_ordinal(node,target_nodes,EXPERIMENT_DIR,device):\n",
    "        verbose=False\n",
    "        n=1000\n",
    "        #### 0.  paths\n",
    "        NODE_DIR = os.path.join(EXPERIMENT_DIR, f'{node}')\n",
    "        \n",
    "        ##### 1.  load model \n",
    "        model_path = os.path.join(NODE_DIR, \"best_model.pt\")\n",
    "        tram_model = get_fully_specified_tram_model_v2(node, target_nodes, verbose=verbose)\n",
    "        tram_model = tram_model.to(device)\n",
    "        tram_model.load_state_dict(torch.load(model_path))\n",
    "        _, ordered_transformation_terms_in_h, _=ordered_parents(node, target_nodes)\n",
    "        \n",
    "        #### 2. Sampling Dataloader\n",
    "        dataset = SamplingDataset(node=node,EXPERIMENT_DIR=EXPERIMENT_DIR,number_of_samples=n, target_nodes=target_nodes, transform=None)\n",
    "        sample_loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "        output_list = []\n",
    "        with torch.no_grad():\n",
    "            for x in tqdm(sample_loader, desc=f\"h() for  {node}\"):\n",
    "                x = [xi.to(device) for xi in x]\n",
    "                int_input, shift_list = preprocess_inputs(x,ordered_transformation_terms_in_h, device=device)\n",
    "                model_outputs = tram_model(int_input=int_input, shift_input=shift_list)\n",
    "                output_list.append(model_outputs)\n",
    "                break\n",
    "        if verbose:\n",
    "            print(\"source node, Defaults to SI and 1 as inputs\")\n",
    "            \n",
    "        int_out =     output_list[0]['int_out'][0]  # Shape: (20,)\n",
    "        \n",
    "        theta_single=transform_intercepts_ordinal(int_out)\n",
    "        thetas_expanded = theta_single.repeat(n, 1).to(device)  # Shape: (n, 20)\n",
    "        return thetas_expanded\n",
    "        \n",
    "        \n",
    "thetas_expanded=show_hdag_for_single_source_node_ordinal('x1',target_nodes,EXPERIMENT_DIR,device)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_trafo_standart_logistic_v2(target_nodes, EXPERIMENT_DIR, train_df, val_df, device, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e17a4b",
   "metadata": {},
   "source": [
    "### Coefficient estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # enable 3D plotting\n",
    "\n",
    "# --- Your existing setup ---\n",
    "verbose    = False\n",
    "batch_size = 4112\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# this x is only for overlaying your target curve in 2D plots\n",
    "x1d = torch.linspace(-1, 1, steps=1000).unsqueeze(1).to(device)  # (1000, 1)\n",
    "def f(x):\n",
    "    return 0.75 * np.arctan(5 * (x + 0.12))\n",
    "\n",
    "for node in target_nodes:\n",
    "    print(f\"\\n---- check CS of {node} ----\")\n",
    "    if target_nodes[node]['node_type'] == 'source':\n",
    "        print(\"Node type: source — skipping.\")\n",
    "        continue\n",
    "\n",
    "    # load your model\n",
    "    NODE_DIR   = os.path.join(EXPERIMENT_DIR, node)\n",
    "    model_path = os.path.join(NODE_DIR, \"best_model.pt\")\n",
    "    tram_model = get_fully_specified_tram_model(node, target_nodes, verbose=verbose).to(device)\n",
    "    tram_model.load_state_dict(torch.load(model_path))\n",
    "    tram_model.eval()\n",
    "\n",
    "\n",
    "    for i, module in enumerate(tram_model.nn_shift):\n",
    "        name = module.__class__.__name__\n",
    "        print(f\"\\nModule {i}: {name}\")\n",
    "        print(module)\n",
    "\n",
    "        if name == 'LinearShift':\n",
    "            print(\"  LinearShift weights:\")\n",
    "            print(module.fc.weight.data)\n",
    "            continue\n",
    "\n",
    "        # read wanted input dims\n",
    "        in_feats = module.fc1.in_features\n",
    "        print(f\"  expects input shape = (batch_size, {in_feats})\")\n",
    "\n",
    "        # 2-input case → 3D surface plot\n",
    "        if in_feats == 2:\n",
    "            N = 100\n",
    "            a = torch.linspace(-0, 2, steps=N, device=device)\n",
    "            b = torch.linspace(-0, 2, steps=N, device=device)\n",
    "            A, B = torch.meshgrid(a, b, indexing='ij')       # both (N, N)\n",
    "            grid = torch.stack([A, B], dim=-1).view(-1, 2)   # (N*N, 2)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                Y = module(grid).view(N, N).cpu().numpy()    # back to (N, N)\n",
    "\n",
    "            A_np = A.cpu().numpy()\n",
    "            B_np = B.cpu().numpy()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax  = fig.add_subplot(111, projection='3d')\n",
    "            ax.plot_surface(A_np, B_np, Y, cmap='viridis', edgecolor='none')\n",
    "            ax.set_xlabel('input 1')\n",
    "            ax.set_ylabel('input 2')\n",
    "            ax.set_zlabel(f'{name}(x₁, x₂)')\n",
    "            ax.set_title(f\"{node} | Module {i}: {name} (3D surface)\")\n",
    "            plt.show()\n",
    "\n",
    "        # 1-input case → 2D scatter\n",
    "        else:\n",
    "            N = 1000\n",
    "            lin = torch.linspace(-1, 1, steps=N, device=device)\n",
    "            dummy = lin.unsqueeze(1).repeat(1, in_feats)      # (N, in_feats)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y = module(dummy).squeeze().cpu().numpy()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.scatter(dummy[:, 0].cpu().numpy(), y, s=5, label=f\"{name} output\")\n",
    "            # overlay target\n",
    "            plt.scatter(x1d.cpu().numpy(), -f(x1d.cpu().numpy()), c=\"red\", s=5, label=\"target\")\n",
    "            plt.xlabel(\"input value\")\n",
    "            plt.ylabel(\"output value\")\n",
    "            plt.title(f\"{node} | Module {i}: {name} (2D)\")\n",
    "            plt.legend()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eeb428",
   "metadata": {},
   "source": [
    "# 7. Sample from Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_full_dag_chandru(target_nodes_dict,\n",
    "                            EXPERIMENT_DIR,\n",
    "                            device,\n",
    "                            do_interventions={},\n",
    "                            n= 10_000,\n",
    "                            batch_size = 32,\n",
    "                            delete_all_previously_sampled=True,\n",
    "                            verbose=True):\n",
    "    \"\"\"\n",
    "    Samples data for all nodes in a DAG defined by `conf_dict`, ensuring that each node's\n",
    "    parents are sampled before the node itself. Supports interventions on any subset of nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conf_dict : dict\n",
    "        Dictionary defining the DAG. Each key is a node name, and each value is a config\n",
    "        dict that includes at least:\n",
    "            - 'node_type': str, either 'source' or other\n",
    "            - 'parents': list of parent node names\n",
    "            - 'min': float, minimum allowed value for the node\n",
    "            - 'max': float, maximum allowed value for the node\n",
    "\n",
    "    EXPERIMENT_DIR : str\n",
    "        Base directory where all per-node directories are located.\n",
    "\n",
    "    device : torch.device\n",
    "        The device to run computations on (e.g., 'cuda' or 'cpu').\n",
    "\n",
    "    do_interventions : dict, optional\n",
    "        A dictionary specifying interventions for some nodes. Keys are node names (str),\n",
    "        values are floats. For each intervened node, the specified value is used as the\n",
    "        sampled value for all samples, and the model is bypassed. e.g. {'x1':1.0}\n",
    "\n",
    "    n : int, optional\n",
    "        Number of samples to draw for each node (default is 10_000).\n",
    "\n",
    "    batch_size : int, optional\n",
    "        Batch size for model evaluation during sampling (default is 32).\n",
    "\n",
    "    delete_all_previously_sampled : bool, optional\n",
    "        If True, removes previously sampled data before starting (default is True).\n",
    "\n",
    "    verbose : bool, optional\n",
    "        If True, prints debug/status information (default is True).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function ensures that nodes are only sampled after their parents.\n",
    "    - Nodes with `node_type='source'` are treated as having no parents.\n",
    "    - If a node is in `do_interventions`, `sampled_chandrupatla.pt` and a dummy `latents.pt`\n",
    "      are created, enabling downstream nodes to proceed.\n",
    "    - Sampling is done using a vectorized root-finding method (Chandrupatla's algorithm).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # delete the previolusly sampled data\n",
    "    if delete_all_previously_sampled:\n",
    "        delete_all_samplings(target_nodes_dict, EXPERIMENT_DIR)\n",
    "    \n",
    "    \n",
    "    # repeat process until all nodes are sampled\n",
    "    processed_nodes=[] # stack\n",
    "    while set(processed_nodes) != set(target_nodes_dict.keys()): \n",
    "        for node in target_nodes_dict: # for each node in the conf dict\n",
    "            if node in processed_nodes:\n",
    "                if verbose :\n",
    "                    print('node is already  in sampled list')\n",
    "                continue\n",
    "            \n",
    "            _, ordered_transformation_terms_in_h, _=ordered_parents(node, target_nodes_dict)\n",
    "\n",
    "            \n",
    "            print(f'\\n----*----------*-------------*--------Sample Node: {node} ------------*-----------------*-------------------*--') \n",
    "            \n",
    "            ## 1. Paths \n",
    "            NODE_DIR = os.path.join(EXPERIMENT_DIR, f'{node}')\n",
    "            SAMPLING_DIR = os.path.join(NODE_DIR, 'sampling')\n",
    "            os.makedirs(SAMPLING_DIR, exist_ok=True)\n",
    "            \n",
    "            \n",
    "            ## 2. Check if sampled and latents already exist \n",
    "            if check_sampled_and_latents(NODE_DIR, rootfinder='chandrupatla', verbose=verbose):\n",
    "                processed_nodes.append(node)\n",
    "                continue\n",
    "            \n",
    "            ## 3. logic to make sure parents are always sampled first\n",
    "            skipping_node = False\n",
    "            if target_nodes_dict[node]['node_type'] != 'source':\n",
    "                for parent in target_nodes_dict[node]['parents']:\n",
    "                    if not check_sampled_and_latents(os.path.join(EXPERIMENT_DIR, parent), rootfinder='chandrupatla', verbose=verbose):\n",
    "                        skipping_node = True\n",
    "                        break\n",
    "                    \n",
    "            if skipping_node:\n",
    "                print(f\"Skipping {node} as parent {parent} is not sampled yet.\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            ## INTERVENTION, if node is to be intervened on , data is just saved\n",
    "            if node in do_interventions.keys():\n",
    "                intervention_value = do_interventions[node]\n",
    "                intervention_vals = torch.full((n,), intervention_value)\n",
    "                sampled_path = os.path.join(SAMPLING_DIR, \"sampled_chandrupatla.pt\")\n",
    "                torch.save(intervention_vals, sampled_path)\n",
    "                ### dummy latents jsut for the check , not needed\n",
    "                dummy_latents = torch.full((n,), float('nan'))  \n",
    "                latents_path = os.path.join(SAMPLING_DIR, \"latents.pt\")\n",
    "                torch.save(dummy_latents, latents_path)\n",
    "                processed_nodes.append(node)\n",
    "                \n",
    "            ## no intervention, based on the sampled data from the parents though the latents for each node the observational distribution is generated    \n",
    "            else:\n",
    "                ### sampling latents\n",
    "                latent_sample = torch.tensor(logistic.rvs(size=n), dtype=torch.float32).to(device)\n",
    "                #latent_sample = truncated_logistic_sample(n=n, low=0, high=1, device=device)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"-- sampled latents\")\n",
    "                \n",
    "                ### load modelweights\n",
    "                model_path = os.path.join(NODE_DIR, \"best_model.pt\")\n",
    "                tram_model = get_fully_specified_tram_model(node, target_nodes_dict, verbose=verbose).to(device)\n",
    "                tram_model.load_state_dict(torch.load(model_path))\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"-- loaded modelweights\")\n",
    "                \n",
    "                \n",
    "                # TODO samples for ordinal target\n",
    "                \n",
    "                if \n",
    "                    \n",
    "                dataset = SamplingDataset(node=node, EXPERIMENT_DIR=EXPERIMENT_DIR, rootfinder='chandrupatla', number_of_samples=n, conf_dict=target_nodes_dict, transform=None)\n",
    "                sample_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                \n",
    "                output_list = []\n",
    "                with torch.no_grad():\n",
    "                    for x in tqdm(sample_loader, desc=f\"h() for samples in  {node}\"):\n",
    "                        x = [xi.to(device) for xi in x]\n",
    "                        \n",
    "                        print(f\"x {x}\")\n",
    "                        int_input, shift_list = preprocess_inputs(x,ordered_transformation_terms_in_h.values(), device=device)\n",
    "                        \n",
    "                    \n",
    "                        if int_input is not None:\n",
    "                            print(f\"int_input {int_input.shape}\")\n",
    "                        if shift_list is not None:\n",
    "                            print(f\"shift_list {[s.shape for s in shift_list]}\") \n",
    "                        \n",
    "                        print([t.shape for t in x])\n",
    "                        \n",
    "                        model_outputs = tram_model(int_input=int_input, shift_input=shift_list)\n",
    "                        \n",
    "                        print(f\"model_outputs {model_outputs}\")\n",
    "                        \n",
    "                        output_list.append(model_outputs)\n",
    "                        \n",
    "                if target_nodes_dict[node]['node_type'] == 'source':\n",
    "                    if verbose:\n",
    "                        print(\"source node, Defaults to SI and 1 as inputs\")\n",
    "                    theta_single = output_list[0]['int_out'][0]\n",
    "                    theta_single = transform_intercepts_continous(theta_single)\n",
    "                    thetas_expanded = theta_single.repeat(n, 1)\n",
    "                    shifts = torch.zeros(n, device=device)\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(\"node has parents, previously sampled data is loaded for each pa(node)\")\n",
    "                    y_pred = merge_outputs(output_list, skip_nan=True)\n",
    "                    shifts = y_pred['shift_out']\n",
    "                    if shifts is None:\n",
    "                        print(\"shift_out was None; defaulting to zeros.\")\n",
    "                        shifts = torch.zeros(n, device=device)\n",
    "                    thetas = y_pred['int_out']\n",
    "                    thetas_expanded = transform_intercepts_continous(thetas).squeeze()\n",
    "                    shifts = shifts.squeeze()\n",
    "                \n",
    "                \n",
    "                \n",
    "                low = torch.full((n,), -1e5, device=device)\n",
    "                high = torch.full((n,), 1e5, device=device)\n",
    "                min_vals = torch.tensor(target_nodes_dict[node]['min'], dtype=torch.float32).to(device)\n",
    "                max_vals = torch.tensor(target_nodes_dict[node]['max'], dtype=torch.float32).to(device)\n",
    "                min_max = torch.stack([min_vals, max_vals], dim=0)\n",
    "                \n",
    "                ## Root finder using Chandrupatla's method\n",
    "                def f_vectorized(targets):\n",
    "                    return vectorized_object_function(\n",
    "                        thetas_expanded,\n",
    "                        targets,\n",
    "                        shifts,\n",
    "                        latent_sample,\n",
    "                        k_min=min_max[0],\n",
    "                        k_max=min_max[1]\n",
    "                    )\n",
    "                    \n",
    "                root = chandrupatla_root_finder(\n",
    "                    f_vectorized,\n",
    "                    low,\n",
    "                    high,\n",
    "                    max_iter=10_000,\n",
    "                    tol=1e-9\n",
    "                )\n",
    "                \n",
    "                ## Saving\n",
    "                sampled_path = os.path.join(SAMPLING_DIR, \"sampled_chandrupatla.pt\")\n",
    "                latents_path = os.path.join(SAMPLING_DIR, \"latents.pt\")\n",
    "                \n",
    "                if torch.isnan(root).any():\n",
    "                    print(f'Caution! Sampling for {node} consists of NaNs')\n",
    "                    \n",
    "                torch.save(root, sampled_path)\n",
    "                torch.save(latent_sample, latents_path)\n",
    "                \n",
    "                processed_nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_full_dag_chandru(target_nodes,\n",
    "                            EXPERIMENT_DIR,\n",
    "                            device,\n",
    "                            n= 100,\n",
    "                            batch_size = 2,\n",
    "                            delete_all_previously_sampled=True,\n",
    "                            verbose=True)     \n",
    "\n",
    "# TODO Fix bug with x6 sampling , training works, sampling has issue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0068c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training funktionerit \n",
    "#   (nn_int): ComplexInterceptDefaultTabular(\n",
    "#     (fc1): Linear(in_features=2, out_features=8, bias=True)\n",
    "#     (relu1): ReLU()\n",
    "#     (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
    "#     (relu2): ReLU()\n",
    "#     (fc3): Linear(in_features=8, out_features=20, bias=False)\n",
    "#   )\n",
    "#   (nn_shift): ModuleList(\n",
    "#     (0-1): 2 x ComplexShiftDefaultTabular(\n",
    "#       (fc1): Linear(in_features=1, out_features=64, bias=True)\n",
    "#       (relu1): ReLU()\n",
    "#       (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
    "#       (relu2): ReLU()\n",
    "#       (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
    "#       (relu3): ReLU()\n",
    "#       (fc4): Linear(in_features=64, out_features=1, bias=False)\n",
    "#     )\n",
    "#     (2): LinearShift(\n",
    "#       (fc): Linear(in_features=1, out_features=1, bias=False)\n",
    "#     )\n",
    "#   )\n",
    "# )\n",
    "# Existing model found. Loading weights and history...\n",
    "# Continuing training from epoch 3...\n",
    "# int_input torch.Size([512, 2])  \n",
    "# \n",
    "# shift_list [torch.Size([512, 1]), torch.Size([512, 1]), torch.Size([512, 1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## sampling does not work\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fc3ba",
   "metadata": {},
   "source": [
    "## 7.3 Inspect Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples_vs_true(test_df,target_nodes,EXPERIMENT_DIR,rootfinder='chandrupatla')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6be30f",
   "metadata": {},
   "source": [
    "## 7.4 Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return -0.3*x  \n",
    "\n",
    "intervention_df=dgp(10_000, doX=[-1.0, None, None], seed=-1)\n",
    "sns.pairplot(intervention_df)\n",
    "plt.suptitle(\"\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_full_dag_chandru(target_nodes,\n",
    "                            EXPERIMENT_DIR,\n",
    "                            device,\n",
    "                            do_interventions={'x1':-1.0},\n",
    "                            n= 10_000,\n",
    "                            batch_size = 32,\n",
    "                            delete_all_previously_sampled=True,\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples_vs_true(intervention_df,target_nodes,EXPERIMENT_DIR,rootfinder='chandrupatla')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tramdag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
