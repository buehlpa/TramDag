{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import logistic\n",
    "from scipy.special import logit\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Train with GPU support.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"No GPU found, train with CPU support.\")\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# own utils\n",
    "from utils.graph import *\n",
    "from utils.tram_models import *\n",
    "from utils.tram_model_helpers import *\n",
    "from utils.tram_data import *\n",
    "from utils.continous import *\n",
    "from utils.sampling_tram_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549c1f0",
   "metadata": {},
   "source": [
    "# 1. Experiments and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"dev_multiinput\"   ## <--- set experiment name\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "\n",
    "LOG_DIR=\"/home/bule/TramDag/dev_experiment_logs\"\n",
    "EXPERIMENT_DIR = os.path.join(LOG_DIR, experiment_name)\n",
    "DATA_PATH = EXPERIMENT_DIR # <----------- change to different source if needed\n",
    "CONF_DICT_PATH = os.path.join(EXPERIMENT_DIR, f\"configuration.json\")\n",
    "\n",
    "os.makedirs(EXPERIMENT_DIR,exist_ok=True)\n",
    "# check if configration dict already exists if not create:\n",
    "\n",
    "if os.path.exists(CONF_DICT_PATH):\n",
    "    configuration_dict=load_configuration_dict(CONF_DICT_PATH)\n",
    "    print(f\"Loaded existing configuration from {CONF_DICT_PATH}\")\n",
    "else:\n",
    "    configuration_dict=create_and_write_new_configuration_dict(experiment_name,CONF_DICT_PATH,EXPERIMENT_DIR,DATA_PATH,LOG_DIR)\n",
    "    print(f\"Created new configuration file at {CONF_DICT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664e730",
   "metadata": {},
   "source": [
    "# 2.  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af45250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO develop meaningful experiment for interactions\n",
    "\n",
    "\n",
    "\n",
    "# Fz(z)=Fy(y)\n",
    "# Fz(h(y|x))=Fy(y)    | z= h(y|x)\n",
    "\n",
    "# Generate x2\n",
    "\n",
    "# h(y|x1,x2,x3,x4,x5)= Bernsteinpol(x1,x2) +f2(x2,x3) + f3(x4, x2) + beta * x5        | bernsteinpol is just linearized assumed with a constant factor say 0.42\n",
    "# h(y|x1,x2,x3,x4,x5)= Bernsteinpol(x1,x2) +f2(x2,x3) + f3(x4, x2) + beta * x5                                          | replace h(y|..) with z\n",
    "# z                  = 0.42*x2 + beta2 * x1                                           | reformulate to x2\n",
    "# x2                 = (z-beta2 * x1 )/0.42                                           | sample z from standart logistic via uniform and logit(np.random.uniform(size=n_obs))\n",
    "# x2                 = (z-beta2 * x1 )/0.42                                           | set beta = 2 (on the edge of the graph)\n",
    "# x2                 = (z-2 * x1 )/0.42                                               |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a8c9e8",
   "metadata": {},
   "source": [
    "### random dgp for testing model pipeline workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "# Define the functions used in the DGP\n",
    "def f1(x1, x2):\n",
    "    return np.sin(np.pi * x1) * np.cos(np.pi * x2)\n",
    "\n",
    "def f2(x2, x3):\n",
    "    return np.exp(-((x2 - 1)**2 + (x3 - 1)**2))\n",
    "\n",
    "def f3(x4, x2):\n",
    "    return (x4 * x2) / (1 + x4**2 + x2**2)\n",
    "\n",
    "def dgp_continuous_interactions(n_obs=10000, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Independent variables\n",
    "    x1 = np.random.uniform(0, 2, size=n_obs)\n",
    "    x2 = np.random.uniform(0, 2, size=n_obs)\n",
    "    x3 = np.random.uniform(0, 2, size=n_obs)\n",
    "    x4 = np.random.uniform(0, 2, size=n_obs)\n",
    "    x5 = np.random.normal(0, 1, size=n_obs)\n",
    "\n",
    "    # Response variable with interactions\n",
    "    y = f1(x1, x2) + f2(x2, x3) + f3(x4, x2) + 1.5 * x5\n",
    "\n",
    "    df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4, 'x5': x5, 'x6': y})\n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "df = dgp_continuous_interactions()\n",
    "\n",
    "# Visualize the 3 interaction functions\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "# f1(x1, x2)\n",
    "ax = fig.add_subplot(131, projection='3d')\n",
    "x = np.linspace(0, 2, 50)\n",
    "y = np.linspace(0, 2, 50)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f1(X, Y)\n",
    "ax.plot_surface(X, Y, Z, alpha=0.8)\n",
    "ax.set_title(\"f1(x1, x2) = sin(pi*x1)*cos(pi*x2)\")\n",
    "ax.set_xlabel(\"x1\")\n",
    "ax.set_ylabel(\"x2\")\n",
    "ax.set_zlabel(\"f1\")\n",
    "\n",
    "# f2(x2, x3)\n",
    "ax = fig.add_subplot(132, projection='3d')\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f2(X, Y)\n",
    "ax.plot_surface(X, Y, Z, alpha=0.8)\n",
    "ax.set_title(\"f2(x2, x3) = exp(-((x2-1)^2 + (x3-1)^2))\")\n",
    "ax.set_xlabel(\"x2\")\n",
    "ax.set_ylabel(\"x3\")\n",
    "ax.set_zlabel(\"f2\")\n",
    "\n",
    "# f3(x4, x2)\n",
    "ax = fig.add_subplot(133, projection='3d')\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f3(X, Y)\n",
    "ax.plot_surface(X, Y, Z, alpha=0.8)\n",
    "ax.set_title(\"f3(x4, x2) = (x4*x2)/(1+x4^2+x2^2)\")\n",
    "ax.set_xlabel(\"x4\")\n",
    "ax.set_ylabel(\"x2\")\n",
    "ax.set_zlabel(\"f3\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a0d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgp(n_obs=10_000, n_vars=6, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a synthetic dataset with n_vars variables and n_obs observations,\n",
    "    where each variable contains a constant value: x2 = 2, x3 = 3, ..., x{n_vars+1} = n_vars+1.\n",
    "\n",
    "    Args:\n",
    "        n_obs (int): Number of observations (rows).\n",
    "        n_vars (int): Number of variables (columns).\n",
    "        seed (int or None): Random seed (not used here since data is deterministic).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Generated dataset.\n",
    "    \"\"\"\n",
    "    values = np.arange(2, 2 + n_vars)  # [2, 3, ..., n_vars + 1]\n",
    "    data = np.tile(values, (n_obs, 1))  # Repeat each value across n_obs rows\n",
    "    columns = [f\"x{i+1}\" for i in range(n_vars)]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df\n",
    "\n",
    "df =dgp(n_obs=10_000, n_vars=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad39c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# 2. Compute quantiles from training data\n",
    "quantiles = train_df.quantile([0.05, 0.95])\n",
    "min_vals = quantiles.loc[0.05]\n",
    "max_vals = quantiles.loc[0.95]\n",
    "\n",
    "# 3. Normalize all sets using training quantiles\n",
    "def normalize_with_quantiles(df, min_vals, max_vals):\n",
    "    return (df - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "# train_df = normalize_with_quantiles(train_df, min_vals, max_vals)\n",
    "# val_df = normalize_with_quantiles(val_df, min_vals, max_vals)\n",
    "# test_df = normalize_with_quantiles(test_df, min_vals, max_vals)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.remove(os.path.join(EXPERIMENT_DIR, \"adj_matrix.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db765d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Editable Parameters ---\n",
    "variable_names = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6']\n",
    "data_type={'x1':'cont','x2':'cont','x3':'cont','x4':'cont','x5':'cont','x6':'cont'}  # continous , images , ordinal\n",
    "\n",
    "interactive_adj_matrix(CONF_DICT_PATH ,seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x6~ci(x2,x3)+cs(x1,x5)+cs(x4,x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = np.load(os.path.join(EXPERIMENT_DIR, \"adj_matrix.npy\"),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea66f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f05182",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_names_matrix= create_nn_model_names(adj_matrix,data_type)\n",
    "nn_names_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dict=get_nodes_dict(adj_matrix, nn_names_matrix, data_type, min_vals, max_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c24f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_dict=get_configuration_dict(adj_matrix,nn_names_matrix, data_type)\n",
    "# # write min max to conf dict\n",
    "# for i,node in enumerate(data_type.keys()):\n",
    "#     conf_dict[node]['min']=min_vals[i].tolist()\n",
    "#     conf_dict[node]['max']=max_vals[i].tolist()\n",
    "# conf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff13326",
   "metadata": {},
   "source": [
    "ordered paretns check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd869c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_parents_datatype, ordered_transformation_terms_in_h, ordered_transformation_term_nn_models_in_h=ordered_parents(node, conf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_parents_datatype\n",
    "ordered_transformation_terms_in_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad32a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_transformation_term_nn_models_in_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adee85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_dataloader(\"x6\", conf_dict, train_df, val_df, batch_size=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tramdag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
