{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b6c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] TramDagModel using device: cpu\n",
      "\n",
      "[INFO] Building model for node 'x1' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x2' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x3' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x4' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x5' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x6' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x7' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "from utils.tramdag import *\n",
    "\n",
    "\n",
    "X, _ = make_blobs(n_samples=100_000,centers=3, n_features=7)\n",
    "df = pd.DataFrame(X, columns=[\"x1\", \"x2\", \"x3\",\"x4\", \"x5\", \"x6\", \"x7\"])\n",
    "\n",
    "# 1. Split the data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "cfg = TramDagConfig.load(\"/home/bule/TramDag/dev_experiment_logs/create_configration_test3/configuration.json\")\n",
    "# cfg.plot_dag()\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "\n",
    "td_model = TramDagModel.from_config(cfg, set_initial_weights=False,verbose=True,debug=True,device=device) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7606d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3726586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] sample(): device: cpu\n",
      "[INFO] Starting full DAG sampling with 10000 samples per node.\n",
      "[DEBUG] sample_full_dag: device: cpu\n",
      "[INFO] Deleting all previously sampled data.\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x1/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x2/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x3/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x4/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x5/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x6/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x7/sampling\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x1 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node x1 from standard logistic distribution\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 1)\n",
      "[WARNING] target_col 'x1' not in DataFrame columns — is this intended to be used as a Sampler?\n",
      "[DEBUG] target_col 'x1' not found in DataFrame columns\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] sample_continous_modelled_target: source node, defaults to SI and 1 as inputs\n",
      "[DEBUG] sample_continous_modelled_target: beginning root finding\n",
      "[DEBUG] sample_continous_modelled_target: thetas_expanded shape: torch.Size([10000, 20])\n",
      "[DEBUG] sample_continous_modelled_target: shifts shape: torch.Size([10000])\n",
      "[DEBUG] sample_continous_modelled_target: latent_sample shape: torch.Size([10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chandrupatla root finding: 100%|██████████| 10000/10000 [00:47<00:00, 210.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] sample_continous_modelled_target: root finding complete. Sampled shape: torch.Size([10000])\n",
      "[INFO] Completed sampling for node 'x1'\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x2 ------------*-----------------*-------------------*--\n",
      "[DEBUG] check_sampled_and_latents: Found 'sampled.pt' in /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x1/sampling\n",
      "[DEBUG] check_sampled_and_latents: Found 'latents.pt' in /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x1/sampling\n",
      "[INFO] Sampling new latents for node x2 from standard logistic distribution\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/bule/TramDag/dev_experiment_logs/create_configration_test3/x2/best_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TramDag/utils/tramdag.py:965\u001b[0m, in \u001b[0;36mTramDagModel.sample\u001b[0;34m(self, do_interventions, predefined_latent_samples_df, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] sample(): device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# ---- perform sampling ----\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m sampled_by_node, latents_by_node \u001b[38;5;241m=\u001b[39m \u001b[43msample_full_dag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_interventions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_interventions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber_of_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelete_all_previously_sampled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelete_all_previously_sampled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminmax_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminmax_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled_by_node, latents_by_node\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data_helpers.py:967\u001b[0m, in \u001b[0;36msample_full_dag\u001b[0;34m(configuration_dict, EXPERIMENT_DIR, device, do_interventions, predefined_latent_samples_df, number_of_samples, batch_size, delete_all_previously_sampled, verbose, debug, minmax_dict)\u001b[0m\n\u001b[1;32m    965\u001b[0m MODEL_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(NODE_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    966\u001b[0m tram_model \u001b[38;5;241m=\u001b[39m get_fully_specified_tram_model(node, configuration_dict, debug\u001b[38;5;241m=\u001b[39mdebug, device\u001b[38;5;241m=\u001b[39mdevice,verbose\u001b[38;5;241m=\u001b[39mverbose)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 967\u001b[0m tram_model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# isntead of sample loader use Generic Dataset but the df is just to sampled data from befor -> create df for each node\u001b[39;00m\n\u001b[1;32m    970\u001b[0m sampled_df\u001b[38;5;241m=\u001b[39mcreate_df_from_sampled(node, target_nodes_dict, number_of_samples, EXPERIMENT_DIR)\n",
      "File \u001b[0;32m~/anaconda3/envs/tramdag/lib/python3.9/site-packages/torch/serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/tramdag/lib/python3.9/site-packages/torch/serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/tramdag/lib/python3.9/site-packages/torch/serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/bule/TramDag/dev_experiment_logs/create_configration_test3/x2/best_model.pt'"
     ]
    }
   ],
   "source": [
    "td_model.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5330054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] fit(): device: cpu\n",
      "[INFO] Computing new minmax dict from training data...\n",
      "[INFO] Saved new minmax dict to /home/bule/TramDag/dev_experiment_logs/create_configration_test3/min_max_scaling.json\n",
      "\n",
      "[INFO] Training node 'x5' for 2 epochs on cpu\n",
      "[DEBUG] fitrain_val_loop():  device: cpu\n",
      "[INFO] Existing model found. Loading weights and history...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x5': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_model.fit(train_df, val_df,epochs=2,batch_size=100_000,prefetch_factor=0,num_workers=None,verbose=True,debug=True,device=device,train_list=['x5'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tramdag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
