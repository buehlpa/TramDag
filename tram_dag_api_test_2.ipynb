{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b6c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] TramDagModel using device: cpu\n",
      "\n",
      "[INFO] Building model for node 'x1' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x2' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x3' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x4' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x5' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x6' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "\n",
      "[INFO] Building model for node 'x7' with settings: {'set_initial_weights': False, 'debug': True, 'verbose': True, 'device': 'cpu'}\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cpu\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "from utils.tramdag import *\n",
    "\n",
    "\n",
    "X, _ = make_blobs(n_samples=100_000,centers=3, n_features=7)\n",
    "df = pd.DataFrame(X, columns=[\"x1\", \"x2\", \"x3\",\"x4\", \"x5\", \"x6\", \"x7\"])\n",
    "\n",
    "# 1. Split the data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "cfg = TramDagConfig.load(\"/home/bule/TramDag/dev_experiment_logs/create_configration_test3/configuration.json\")\n",
    "# cfg.plot_dag()\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "\n",
    "td_model = TramDagModel.from_config(cfg, set_initial_weights=False,verbose=True,debug=True,device=device) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] TramDagDataset.from_dataframe() called with kwargs:\n",
      "    shuffle: True\n",
      "    epochs: 25\n",
      "    batch_size: 100000\n",
      "    prefetch_factor: None\n",
      "    num_workers: 0\n",
      "    verbose: True\n",
      "    debug: True\n",
      "    device: cpu\n",
      "    use_dataloader: True\n",
      "[DEBUG] Final merged settings (after defaults + overrides):\n",
      "    batch_size: 100000\n",
      "    shuffle: True\n",
      "    num_workers: 0\n",
      "    pin_memory: True\n",
      "    return_intercept_shift: True\n",
      "    debug: True\n",
      "    transform: None\n",
      "    use_dataloader: True\n",
      "    sampler: None\n",
      "    batch_sampler: None\n",
      "    collate_fn: None\n",
      "    drop_last: False\n",
      "    timeout: 0\n",
      "    worker_init_fn: None\n",
      "    multiprocessing_context: None\n",
      "    generator: None\n",
      "    prefetch_factor: None\n",
      "    persistent_workers: False\n",
      "    pin_memory_device: \n",
      "    epochs: 25\n",
      "    verbose: True\n",
      "    device: cpu\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(80000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x1\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(80000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x2\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=['x1']\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=['ls']\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=['x1']\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: [[1]]\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=False\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(80000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x3\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(80000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x4\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(80000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x5\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(80000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x6\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(80000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x7\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=['x2', 'x1', 'x6', 'x4', 'x3', 'x5']\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=['ci11', 'ci12', 'cs', 'cs11', 'cs12', 'ls']\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=['x2', 'x1', 'x6', 'x4', 'x3', 'x5']\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=False\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Intercept indices: [0, 1]\n",
      "[DEBUG] Shift group indices: [[2], [3, 4], [5]]\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=False\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] TramDagDataset.from_dataframe() called with kwargs:\n",
      "    shuffle: False\n",
      "    epochs: 25\n",
      "    batch_size: 100000\n",
      "    prefetch_factor: None\n",
      "    num_workers: 0\n",
      "    verbose: True\n",
      "    debug: True\n",
      "    device: cpu\n",
      "    use_dataloader: True\n",
      "[DEBUG] Final merged settings (after defaults + overrides):\n",
      "    batch_size: 100000\n",
      "    shuffle: False\n",
      "    num_workers: 0\n",
      "    pin_memory: True\n",
      "    return_intercept_shift: True\n",
      "    debug: True\n",
      "    transform: None\n",
      "    use_dataloader: True\n",
      "    sampler: None\n",
      "    batch_sampler: None\n",
      "    collate_fn: None\n",
      "    drop_last: False\n",
      "    timeout: 0\n",
      "    worker_init_fn: None\n",
      "    multiprocessing_context: None\n",
      "    generator: None\n",
      "    prefetch_factor: None\n",
      "    persistent_workers: False\n",
      "    pin_memory_device: \n",
      "    epochs: 25\n",
      "    verbose: True\n",
      "    device: cpu\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x1\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x2\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=['x1']\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=['ls']\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=['x1']\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: [[1]]\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=False\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x3\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x4\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x5\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x6\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 7)\n",
      "[DEBUG] Set target_col: type=<class 'str'>, value=x7\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=['x2', 'x1', 'x6', 'x4', 'x3', 'x5']\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=['ci11', 'ci12', 'cs', 'cs11', 'cs12', 'ls']\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=['x2', 'x1', 'x6', 'x4', 'x3', 'x5']\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=False\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Intercept indices: [0, 1]\n",
      "[DEBUG] Shift group indices: [[2], [3, 4], [5]]\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=False\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] fit(): device: cpu\n",
      "[INFO] Computing new minmax dict from training data...\n",
      "[DEBUG] Make sure to provide only training data to compute_scaling!\n",
      "[DEBUG] No DataFrame provided, using internal df.\n",
      "[INFO] Saved new minmax dict to /home/bule/TramDag/dev_experiment_logs/create_configration_test3/min_max_scaling.json\n",
      "\n",
      "[INFO] Training node 'x1' for 25 epochs on cpu\n",
      "[DEBUG] train_val_loop(): device: cpu\n",
      "[INFO] Existing model found. Loading weights and history...\n",
      "\n",
      "===== Epoch 18/25 =====\n",
      "[INFO] Batch 0 fetch: 2.1288s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0005s\n",
      "[INFO] Loss: 0.0513s\n",
      "[INFO] Backward+Step: 0.0123s\n",
      "[INFO] BATCH 0 Total time: 0.0642s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1406s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0161s\n",
      "[INFO] VAL BATCH 0 Total: 0.0165s\n",
      "[INFO] Saving epoch artifacts: 0.0009s\n",
      "[INFO] Epoch 18: Train NLL=3.8317 | Val NLL=3.8251 | Time=2.35s\n",
      "\n",
      "===== Epoch 19/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0761s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0008s\n",
      "[INFO] Loss: 0.0505s\n",
      "[INFO] Backward+Step: 0.0113s\n",
      "[INFO] BATCH 0 Total time: 0.0628s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1516s\n",
      "[INFO] VAL Forward: 0.0006s\n",
      "[INFO] VAL Loss: 0.0230s\n",
      "[INFO] VAL BATCH 0 Total: 0.0237s\n",
      "[INFO] Saving epoch artifacts: 0.0010s\n",
      "[INFO] Epoch 19: Train NLL=3.8263 | Val NLL=3.8197 | Time=2.32s\n",
      "\n",
      "===== Epoch 20/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0665s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0487s\n",
      "[INFO] Backward+Step: 0.0122s\n",
      "[INFO] BATCH 0 Total time: 0.0616s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1464s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0148s\n",
      "[INFO] VAL BATCH 0 Total: 0.0152s\n",
      "[INFO] Saving epoch artifacts: 0.0009s\n",
      "[INFO] Epoch 20: Train NLL=3.8208 | Val NLL=3.8142 | Time=2.29s\n",
      "\n",
      "===== Epoch 21/25 =====\n",
      "[INFO] Batch 0 fetch: 1.8600s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0538s\n",
      "[INFO] Backward+Step: 0.0119s\n",
      "[INFO] BATCH 0 Total time: 0.0664s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.3044s\n",
      "[INFO] VAL Forward: 0.0006s\n",
      "[INFO] VAL Loss: 0.0147s\n",
      "[INFO] VAL BATCH 0 Total: 0.0153s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 21: Train NLL=3.8154 | Val NLL=3.8088 | Time=2.25s\n",
      "\n",
      "===== Epoch 22/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0169s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0007s\n",
      "[INFO] Loss: 0.0511s\n",
      "[INFO] Backward+Step: 0.0108s\n",
      "[INFO] BATCH 0 Total time: 0.0627s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1374s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0136s\n",
      "[INFO] VAL BATCH 0 Total: 0.0143s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 22: Train NLL=3.8100 | Val NLL=3.8035 | Time=2.23s\n",
      "\n",
      "===== Epoch 23/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0758s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0494s\n",
      "[INFO] Backward+Step: 0.0122s\n",
      "[INFO] BATCH 0 Total time: 0.0623s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1493s\n",
      "[INFO] VAL Forward: 0.0006s\n",
      "[INFO] VAL Loss: 0.0183s\n",
      "[INFO] VAL BATCH 0 Total: 0.0189s\n",
      "[INFO] Saving epoch artifacts: 0.0008s\n",
      "[INFO] Epoch 23: Train NLL=3.8047 | Val NLL=3.7981 | Time=2.31s\n",
      "\n",
      "===== Epoch 24/25 =====\n",
      "[INFO] Batch 0 fetch: 1.8778s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0675s\n",
      "[INFO] Backward+Step: 0.0136s\n",
      "[INFO] BATCH 0 Total time: 0.0819s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.2886s\n",
      "[INFO] VAL Forward: 0.0007s\n",
      "[INFO] VAL Loss: 0.0180s\n",
      "[INFO] VAL BATCH 0 Total: 0.0187s\n",
      "[INFO] Saving epoch artifacts: 0.0014s\n",
      "[INFO] Epoch 24: Train NLL=3.7993 | Val NLL=3.7928 | Time=2.27s\n",
      "\n",
      "===== Epoch 25/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0441s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0522s\n",
      "[INFO] Backward+Step: 0.0122s\n",
      "[INFO] BATCH 0 Total time: 0.0651s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1410s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0135s\n",
      "[INFO] VAL BATCH 0 Total: 0.0139s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 25: Train NLL=3.7940 | Val NLL=3.7875 | Time=2.27s\n",
      "\n",
      "[INFO] Training node 'x2' for 25 epochs on cpu\n",
      "[DEBUG] train_val_loop(): device: cpu\n",
      "[INFO] Existing model found. Loading weights and history...\n",
      "\n",
      "===== Epoch 18/25 =====\n",
      "[INFO] Batch 0 fetch: 3.1313s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0011s\n",
      "[INFO] Loss: 0.0486s\n",
      "[INFO] Backward+Step: 0.0120s\n",
      "[INFO] BATCH 0 Total time: 0.0618s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.4196s\n",
      "[INFO] VAL Forward: 0.0006s\n",
      "[INFO] VAL Loss: 0.0192s\n",
      "[INFO] VAL BATCH 0 Total: 0.0199s\n",
      "[INFO] Saving epoch artifacts: 0.0015s\n",
      "[INFO] Epoch 18: Train NLL=4.1223 | Val NLL=4.1122 | Time=3.64s\n",
      "\n",
      "===== Epoch 19/25 =====\n",
      "[INFO] Batch 0 fetch: 3.0927s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0012s\n",
      "[INFO] Loss: 0.0515s\n",
      "[INFO] Backward+Step: 0.0132s\n",
      "[INFO] BATCH 0 Total time: 0.0661s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.2572s\n",
      "[INFO] VAL Forward: 0.0006s\n",
      "[INFO] VAL Loss: 0.0180s\n",
      "[INFO] VAL BATCH 0 Total: 0.0187s\n",
      "[INFO] Saving epoch artifacts: 0.0013s\n",
      "[INFO] Epoch 19: Train NLL=4.1152 | Val NLL=4.1059 | Time=3.44s\n",
      "\n",
      "===== Epoch 20/25 =====\n",
      "[INFO] Batch 0 fetch: 3.3414s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0009s\n",
      "[INFO] Loss: 0.0562s\n",
      "[INFO] Backward+Step: 0.0188s\n",
      "[INFO] BATCH 0 Total time: 0.0760s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.3045s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0155s\n",
      "[INFO] VAL BATCH 0 Total: 0.0161s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 20: Train NLL=4.1089 | Val NLL=4.0997 | Time=3.74s\n",
      "\n",
      "===== Epoch 21/25 =====\n",
      "[INFO] Batch 0 fetch: 3.0797s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0005s\n",
      "[INFO] Loss: 0.0497s\n",
      "[INFO] Backward+Step: 0.0119s\n",
      "[INFO] BATCH 0 Total time: 0.0625s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.2524s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0152s\n",
      "[INFO] VAL BATCH 0 Total: 0.0158s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 21: Train NLL=4.1027 | Val NLL=4.0932 | Time=3.41s\n",
      "\n",
      "===== Epoch 22/25 =====\n",
      "[INFO] Batch 0 fetch: 3.0468s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0005s\n",
      "[INFO] Loss: 0.0658s\n",
      "[INFO] Backward+Step: 0.0164s\n",
      "[INFO] BATCH 0 Total time: 0.0831s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.4109s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0206s\n",
      "[INFO] VAL BATCH 0 Total: 0.0212s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 22: Train NLL=4.0962 | Val NLL=4.0867 | Time=3.56s\n",
      "\n",
      "===== Epoch 23/25 =====\n",
      "[INFO] Batch 0 fetch: 3.0640s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0005s\n",
      "[INFO] Loss: 0.0520s\n",
      "[INFO] Backward+Step: 0.0132s\n",
      "[INFO] BATCH 0 Total time: 0.0661s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.2520s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0205s\n",
      "[INFO] VAL BATCH 0 Total: 0.0211s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 23: Train NLL=4.0897 | Val NLL=4.0803 | Time=3.41s\n",
      "\n",
      "===== Epoch 24/25 =====\n",
      "[INFO] Batch 0 fetch: 3.2912s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0005s\n",
      "[INFO] Loss: 0.0485s\n",
      "[INFO] Backward+Step: 0.0129s\n",
      "[INFO] BATCH 0 Total time: 0.0622s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.2516s\n",
      "[INFO] VAL Forward: 0.0008s\n",
      "[INFO] VAL Loss: 0.0145s\n",
      "[INFO] VAL BATCH 0 Total: 0.0154s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 24: Train NLL=4.0832 | Val NLL=4.0740 | Time=3.62s\n",
      "\n",
      "===== Epoch 25/25 =====\n",
      "[INFO] Batch 0 fetch: 2.8997s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0008s\n",
      "[INFO] Loss: 0.0480s\n",
      "[INFO] Backward+Step: 0.0131s\n",
      "[INFO] BATCH 0 Total time: 0.0620s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.3987s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0140s\n",
      "[INFO] VAL BATCH 0 Total: 0.0147s\n",
      "[INFO] Saving epoch artifacts: 0.0008s\n",
      "[INFO] Epoch 25: Train NLL=4.0769 | Val NLL=4.0677 | Time=3.38s\n",
      "\n",
      "[INFO] Training node 'x3' for 25 epochs on cpu\n",
      "[DEBUG] train_val_loop(): device: cpu\n",
      "[INFO] Existing model found. Loading weights and history...\n",
      "\n",
      "===== Epoch 18/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0115s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0486s\n",
      "[INFO] Backward+Step: 0.0122s\n",
      "[INFO] BATCH 0 Total time: 0.0615s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1471s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0186s\n",
      "[INFO] VAL BATCH 0 Total: 0.0191s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 18: Train NLL=4.2985 | Val NLL=4.2950 | Time=2.24s\n",
      "\n",
      "===== Epoch 19/25 =====\n",
      "[INFO] Batch 0 fetch: 1.9930s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0007s\n",
      "[INFO] Loss: 0.0567s\n",
      "[INFO] Backward+Step: 0.0128s\n",
      "[INFO] BATCH 0 Total time: 0.0703s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1429s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0134s\n",
      "[INFO] VAL BATCH 0 Total: 0.0140s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 19: Train NLL=4.2924 | Val NLL=4.2889 | Time=2.22s\n",
      "\n",
      "===== Epoch 20/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0513s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0486s\n",
      "[INFO] Backward+Step: 0.0122s\n",
      "[INFO] BATCH 0 Total time: 0.0614s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1385s\n",
      "[INFO] VAL Forward: 0.0009s\n",
      "[INFO] VAL Loss: 0.0146s\n",
      "[INFO] VAL BATCH 0 Total: 0.0156s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 20: Train NLL=4.2863 | Val NLL=4.2828 | Time=2.27s\n",
      "\n",
      "===== Epoch 21/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0460s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0007s\n",
      "[INFO] Loss: 0.0498s\n",
      "[INFO] Backward+Step: 0.0120s\n",
      "[INFO] BATCH 0 Total time: 0.0627s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1811s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0198s\n",
      "[INFO] VAL BATCH 0 Total: 0.0203s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 21: Train NLL=4.2802 | Val NLL=4.2768 | Time=2.31s\n",
      "\n",
      "===== Epoch 22/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0038s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0475s\n",
      "[INFO] Backward+Step: 0.0125s\n",
      "[INFO] BATCH 0 Total time: 0.0606s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1387s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0166s\n",
      "[INFO] VAL BATCH 0 Total: 0.0170s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 22: Train NLL=4.2742 | Val NLL=4.2707 | Time=2.22s\n",
      "\n",
      "===== Epoch 23/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0024s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0598s\n",
      "[INFO] Backward+Step: 0.0113s\n",
      "[INFO] BATCH 0 Total time: 0.0718s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1389s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0141s\n",
      "[INFO] VAL BATCH 0 Total: 0.0147s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 23: Train NLL=4.2681 | Val NLL=4.2647 | Time=2.23s\n",
      "\n",
      "===== Epoch 24/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0050s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0502s\n",
      "[INFO] Backward+Step: 0.0113s\n",
      "[INFO] BATCH 0 Total time: 0.0622s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1452s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0127s\n",
      "[INFO] VAL BATCH 0 Total: 0.0132s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 24: Train NLL=4.2621 | Val NLL=4.2587 | Time=2.23s\n",
      "\n",
      "===== Epoch 25/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0078s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0498s\n",
      "[INFO] Backward+Step: 0.0105s\n",
      "[INFO] BATCH 0 Total time: 0.0610s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1385s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0151s\n",
      "[INFO] VAL BATCH 0 Total: 0.0157s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 25: Train NLL=4.2561 | Val NLL=4.2528 | Time=2.22s\n",
      "\n",
      "[INFO] Training node 'x4' for 25 epochs on cpu\n",
      "[DEBUG] train_val_loop(): device: cpu\n",
      "[INFO] Existing model found. Loading weights and history...\n",
      "\n",
      "===== Epoch 18/25 =====\n",
      "[INFO] Batch 0 fetch: 1.9954s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0040s\n",
      "[INFO] Loss: 0.0538s\n",
      "[INFO] Backward+Step: 0.0122s\n",
      "[INFO] BATCH 0 Total time: 0.0701s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1457s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0146s\n",
      "[INFO] VAL BATCH 0 Total: 0.0152s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 18: Train NLL=3.9490 | Val NLL=3.9426 | Time=2.23s\n",
      "\n",
      "===== Epoch 19/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0167s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0007s\n",
      "[INFO] Loss: 0.0555s\n",
      "[INFO] Backward+Step: 0.0135s\n",
      "[INFO] BATCH 0 Total time: 0.0698s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1405s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0148s\n",
      "[INFO] VAL BATCH 0 Total: 0.0153s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 19: Train NLL=3.9424 | Val NLL=3.9360 | Time=2.24s\n",
      "\n",
      "===== Epoch 20/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0617s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0486s\n",
      "[INFO] Backward+Step: 0.0111s\n",
      "[INFO] BATCH 0 Total time: 0.0604s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1373s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0146s\n",
      "[INFO] VAL BATCH 0 Total: 0.0150s\n",
      "[INFO] Saving epoch artifacts: 0.0006s\n",
      "[INFO] Epoch 20: Train NLL=3.9358 | Val NLL=3.9294 | Time=2.28s\n",
      "\n",
      "===== Epoch 21/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0377s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0504s\n",
      "[INFO] Backward+Step: 0.0123s\n",
      "[INFO] BATCH 0 Total time: 0.0635s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1704s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0139s\n",
      "[INFO] VAL BATCH 0 Total: 0.0143s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 21: Train NLL=3.9292 | Val NLL=3.9229 | Time=2.29s\n",
      "\n",
      "===== Epoch 22/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0061s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0477s\n",
      "[INFO] Backward+Step: 0.0125s\n",
      "[INFO] BATCH 0 Total time: 0.0608s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1499s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0138s\n",
      "[INFO] VAL BATCH 0 Total: 0.0143s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 22: Train NLL=3.9227 | Val NLL=3.9164 | Time=2.23s\n",
      "\n",
      "===== Epoch 23/25 =====\n",
      "[INFO] Batch 0 fetch: 1.9862s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0003s\n",
      "[INFO] Loss: 0.0588s\n",
      "[INFO] Backward+Step: 0.0138s\n",
      "[INFO] BATCH 0 Total time: 0.0732s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1396s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0144s\n",
      "[INFO] VAL BATCH 0 Total: 0.0149s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 23: Train NLL=3.9161 | Val NLL=3.9099 | Time=2.22s\n",
      "\n",
      "===== Epoch 24/25 =====\n",
      "[INFO] Batch 0 fetch: 2.1579s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0479s\n",
      "[INFO] Backward+Step: 0.0136s\n",
      "[INFO] BATCH 0 Total time: 0.0621s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1471s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0161s\n",
      "[INFO] VAL BATCH 0 Total: 0.0166s\n",
      "[INFO] Saving epoch artifacts: 0.0008s\n",
      "[INFO] Epoch 24: Train NLL=3.9096 | Val NLL=3.9034 | Time=2.39s\n",
      "\n",
      "===== Epoch 25/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0912s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0007s\n",
      "[INFO] Loss: 0.0513s\n",
      "[INFO] Backward+Step: 0.0136s\n",
      "[INFO] BATCH 0 Total time: 0.0657s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1424s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0179s\n",
      "[INFO] VAL BATCH 0 Total: 0.0185s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 25: Train NLL=3.9032 | Val NLL=3.8970 | Time=2.32s\n",
      "\n",
      "[INFO] Training node 'x5' for 25 epochs on cpu\n",
      "[DEBUG] train_val_loop(): device: cpu\n",
      "[INFO] Existing model found. Loading weights and history...\n",
      "\n",
      "===== Epoch 18/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0141s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0497s\n",
      "[INFO] Backward+Step: 0.0117s\n",
      "[INFO] BATCH 0 Total time: 0.0621s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1432s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0151s\n",
      "[INFO] VAL BATCH 0 Total: 0.0157s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 18: Train NLL=4.2647 | Val NLL=4.2585 | Time=2.24s\n",
      "\n",
      "===== Epoch 19/25 =====\n",
      "[INFO] Batch 0 fetch: 2.1102s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0503s\n",
      "[INFO] Backward+Step: 0.0123s\n",
      "[INFO] BATCH 0 Total time: 0.0634s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1457s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0172s\n",
      "[INFO] VAL BATCH 0 Total: 0.0178s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 19: Train NLL=4.2585 | Val NLL=4.2523 | Time=2.34s\n",
      "\n",
      "===== Epoch 20/25 =====\n",
      "[INFO] Batch 0 fetch: 2.1098s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0008s\n",
      "[INFO] Loss: 0.0637s\n",
      "[INFO] Backward+Step: 0.0167s\n",
      "[INFO] BATCH 0 Total time: 0.0814s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1504s\n",
      "[INFO] VAL Forward: 0.0005s\n",
      "[INFO] VAL Loss: 0.0141s\n",
      "[INFO] VAL BATCH 0 Total: 0.0147s\n",
      "[INFO] Saving epoch artifacts: 0.0008s\n",
      "[INFO] Epoch 20: Train NLL=4.2523 | Val NLL=4.2462 | Time=2.36s\n",
      "\n",
      "===== Epoch 21/25 =====\n",
      "[INFO] Batch 0 fetch: 2.1084s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0593s\n",
      "[INFO] Backward+Step: 0.0175s\n",
      "[INFO] BATCH 0 Total time: 0.0776s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1469s\n",
      "[INFO] VAL Forward: 0.0006s\n",
      "[INFO] VAL Loss: 0.0146s\n",
      "[INFO] VAL BATCH 0 Total: 0.0152s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 21: Train NLL=4.2461 | Val NLL=4.2401 | Time=2.35s\n",
      "\n",
      "===== Epoch 22/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0955s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0645s\n",
      "[INFO] Backward+Step: 0.0167s\n",
      "[INFO] BATCH 0 Total time: 0.0819s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1470s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0194s\n",
      "[INFO] VAL BATCH 0 Total: 0.0199s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 22: Train NLL=4.2400 | Val NLL=4.2340 | Time=2.35s\n",
      "\n",
      "===== Epoch 23/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0785s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0004s\n",
      "[INFO] Loss: 0.0727s\n",
      "[INFO] Backward+Step: 0.0127s\n",
      "[INFO] BATCH 0 Total time: 0.0862s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1479s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0188s\n",
      "[INFO] VAL BATCH 0 Total: 0.0194s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 23: Train NLL=4.2339 | Val NLL=4.2279 | Time=2.33s\n",
      "\n",
      "===== Epoch 24/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0043s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0003s\n",
      "[INFO] Loss: 0.0498s\n",
      "[INFO] Backward+Step: 0.0122s\n",
      "[INFO] BATCH 0 Total time: 0.0626s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1466s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0151s\n",
      "[INFO] VAL BATCH 0 Total: 0.0156s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 24: Train NLL=4.2278 | Val NLL=4.2218 | Time=2.23s\n",
      "\n",
      "===== Epoch 25/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0012s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0505s\n",
      "[INFO] Backward+Step: 0.0121s\n",
      "[INFO] BATCH 0 Total time: 0.0632s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1378s\n",
      "[INFO] VAL Forward: 0.0004s\n",
      "[INFO] VAL Loss: 0.0148s\n",
      "[INFO] VAL BATCH 0 Total: 0.0153s\n",
      "[INFO] Saving epoch artifacts: 0.0007s\n",
      "[INFO] Epoch 25: Train NLL=4.2217 | Val NLL=4.2157 | Time=2.22s\n",
      "\n",
      "[INFO] Training node 'x6' for 25 epochs on cpu\n",
      "[DEBUG] train_val_loop(): device: cpu\n",
      "[INFO] Existing model found. Loading weights and history...\n",
      "\n",
      "===== Epoch 18/25 =====\n",
      "[INFO] Batch 0 fetch: 2.1447s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0003s\n",
      "[INFO] Loss: 0.0552s\n",
      "[INFO] Backward+Step: 0.0157s\n",
      "[INFO] BATCH 0 Total time: 0.0715s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1447s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0141s\n",
      "[INFO] VAL BATCH 0 Total: 0.0147s\n",
      "[INFO] Saving epoch artifacts: 0.0008s\n",
      "[INFO] Epoch 18: Train NLL=4.2744 | Val NLL=4.2665 | Time=2.38s\n",
      "\n",
      "===== Epoch 19/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0017s\n",
      "[INFO] Move to device: 0.0002s\n",
      "[INFO] Forward: 0.0003s\n",
      "[INFO] Loss: 0.0489s\n",
      "[INFO] Backward+Step: 0.0121s\n",
      "[INFO] BATCH 0 Total time: 0.0617s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1377s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0148s\n",
      "[INFO] VAL BATCH 0 Total: 0.0152s\n",
      "[INFO] Saving epoch artifacts: 0.0010s\n",
      "[INFO] Epoch 19: Train NLL=4.2687 | Val NLL=4.2608 | Time=2.22s\n",
      "\n",
      "===== Epoch 20/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0094s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0006s\n",
      "[INFO] Loss: 0.0474s\n",
      "[INFO] Backward+Step: 0.0117s\n",
      "[INFO] BATCH 0 Total time: 0.0598s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1450s\n",
      "[INFO] VAL Forward: 0.0007s\n",
      "[INFO] VAL Loss: 0.0198s\n",
      "[INFO] VAL BATCH 0 Total: 0.0206s\n",
      "[INFO] Saving epoch artifacts: 0.0009s\n",
      "[INFO] Epoch 20: Train NLL=4.2629 | Val NLL=4.2551 | Time=2.24s\n",
      "\n",
      "===== Epoch 21/25 =====\n",
      "[INFO] Batch 0 fetch: 2.0088s\n",
      "[INFO] Move to device: 0.0000s\n",
      "[INFO] Forward: 0.0007s\n",
      "[INFO] Loss: 0.0504s\n",
      "[INFO] Backward+Step: 0.0124s\n",
      "[INFO] BATCH 0 Total time: 0.0636s\n",
      "\n",
      "[INFO] VAL Batch 0 fetch: 0.1360s\n",
      "[INFO] VAL Forward: 0.0003s\n",
      "[INFO] VAL Loss: 0.0144s\n",
      "[INFO] VAL BATCH 0 Total: 0.0148s\n",
      "[INFO] Saving epoch artifacts: 0.0008s\n",
      "[INFO] Epoch 21: Train NLL=4.2572 | Val NLL=4.2494 | Time=2.23s\n",
      "\n",
      "===== Epoch 22/25 =====\n"
     ]
    }
   ],
   "source": [
    "td_model.fit(train_df, val_df,epochs=25,batch_size=100_000,prefetch_factor=None,num_workers=0,verbose=True,debug=True,device=device,use_dataloader=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7606d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3726586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] sample(): device: cuda\n",
      "[INFO] Starting full DAG sampling with 10000 samples per node.\n",
      "[DEBUG] sample_full_dag: device: cuda\n",
      "[INFO] Deleting all previously sampled data.\n",
      "Deleted directory: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x1/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x2/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x3/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x4/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x5/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x6/sampling\n",
      "Directory does not exist: /home/bule/TramDag/dev_experiment_logs/create_configration_test3/x7/sampling\n",
      "\n",
      "----*----------*-------------*--------Sample Node: x1 ------------*-----------------*-------------------*--\n",
      "[INFO] Sampling new latents for node x1 from standard logistic distribution\n",
      "[DEBUG] get_fully_specified_tram_model(): device: cuda\n",
      "[DEBUG] default_number_thetas for continuous outcomes: 20\n",
      "[DEBUG] Set df: type=<class 'pandas.core.frame.DataFrame'>, shape=(10000, 1)\n",
      "[WARNING] target_col 'x1' not in DataFrame columns — is this intended to be used as a Sampler?\n",
      "[DEBUG] target_col 'x1' not found in DataFrame columns\n",
      "[DEBUG] Set target_nodes: type=<class 'dict'>, keys=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7']\n",
      "[DEBUG] Set parents_datatype_dict: type=<class 'collections.OrderedDict'>, keys=[]\n",
      "[DEBUG] Set transformation_terms_preprocessing: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set predictors: type=<class 'list'>, value=[]\n",
      "[DEBUG] Set transform: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Set h_needs_simple_intercept: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set target_data_type: type=<class 'str'>, value=continous\n",
      "[DEBUG] Set target_num_classes: type=<class 'NoneType'>, value=None\n",
      "[DEBUG] Inserted simple intercept term 'si'\n",
      "[DEBUG] Intercept indices: [0]\n",
      "[DEBUG] Shift group indices: []\n",
      "[DEBUG] Set target_is_source: type=<class 'bool'>, value=True\n",
      "[DEBUG] Set ordinal_num_classes: type=<class 'dict'>, value={}\n",
      "[DEBUG] _check_multiclass_predictors_of_df: checked multiclass_predicitors passed\n",
      "[DEBUG] _check_ordinal_levels: checked ordinal levels passed\n",
      "[INFO] ------ Initalized all attributes of Genericdataset ------\n",
      "[DEBUG] sample_continous_modelled_target: source node, defaults to SI and 1 as inputs\n",
      "[DEBUG] sample_continous_modelled_target: beginning root finding\n",
      "[DEBUG] sample_continous_modelled_target: thetas_expanded shape: torch.Size([10000, 20])\n",
      "[DEBUG] sample_continous_modelled_target: shifts shape: torch.Size([10000])\n",
      "[DEBUG] sample_continous_modelled_target: latent_sample shape: torch.Size([10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chandrupatla root finding:  25%|██▍       | 2482/10000 [00:05<00:15, 492.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TramDag/utils/tramdag.py:969\u001b[0m, in \u001b[0;36mTramDagModel.sample\u001b[0;34m(self, do_interventions, predefined_latent_samples_df, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] sample(): device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;66;03m# ---- perform sampling ----\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m sampled_by_node, latents_by_node \u001b[38;5;241m=\u001b[39m \u001b[43msample_full_dag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_interventions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_interventions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_latent_samples_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber_of_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelete_all_previously_sampled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelete_all_previously_sampled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminmax_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminmax_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled_by_node, latents_by_node\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data_helpers.py:983\u001b[0m, in \u001b[0;36msample_full_dag\u001b[0;34m(configuration_dict, EXPERIMENT_DIR, device, do_interventions, predefined_latent_samples_df, number_of_samples, batch_size, delete_all_previously_sampled, verbose, debug, minmax_dict)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m###*************************************************** Continous Modelled Outcome ************************************************\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_outcome_modelled_continous(node,target_nodes_dict):\n\u001b[0;32m--> 983\u001b[0m     sampled\u001b[38;5;241m=\u001b[39m\u001b[43msample_continous_modelled_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_nodes_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtram_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlatent_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\u001b[43mminmax_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminmax_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m###*************************************************** Ordinal Modelled Outcome ************************************************\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_outcome_modelled_ordinal(node,target_nodes_dict):\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data_helpers.py:631\u001b[0m, in \u001b[0;36msample_continous_modelled_target\u001b[0;34m(node, target_nodes_dict, sample_loader, tram_model, latent_sample, device, debug, minmax_dict)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorized_object_function(\n\u001b[1;32m    622\u001b[0m         thetas_expanded,\n\u001b[1;32m    623\u001b[0m         targets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m         k_max\u001b[38;5;241m=\u001b[39mmin_max[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    628\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# Root finding\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m sampled \u001b[38;5;241m=\u001b[39m \u001b[43mchandrupatla_root_finder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf_vectorized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-12\u001b[39;49m\n\u001b[1;32m    637\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(sampled)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoot finding failed: returned None or contains NaNs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/TramDag/utils/loss_continous.py:399\u001b[0m, in \u001b[0;36mchandrupatla_root_finder\u001b[0;34m(f, low, high, max_iter, tol)\u001b[0m\n\u001b[1;32m    391\u001b[0m fallback \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     (s \u001b[38;5;241m<\u001b[39m torch\u001b[38;5;241m.\u001b[39mminimum(a, b)) \u001b[38;5;241m|\u001b[39m\n\u001b[1;32m    393\u001b[0m     (s \u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mmaximum(a, b)) \u001b[38;5;241m|\u001b[39m\n\u001b[1;32m    394\u001b[0m     (torch\u001b[38;5;241m.\u001b[39mabs(s \u001b[38;5;241m-\u001b[39m b) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(b \u001b[38;5;241m-\u001b[39m c) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m|\u001b[39m\n\u001b[1;32m    395\u001b[0m     (torch\u001b[38;5;241m.\u001b[39mabs(b \u001b[38;5;241m-\u001b[39m c) \u001b[38;5;241m<\u001b[39m tol)\n\u001b[1;32m    396\u001b[0m )\n\u001b[1;32m    397\u001b[0m s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(fallback, s_bisect, s)\n\u001b[0;32m--> 399\u001b[0m fs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m c, fc \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mclone(), fb\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    402\u001b[0m use_lower \u001b[38;5;241m=\u001b[39m (fa \u001b[38;5;241m*\u001b[39m fs \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/TramDag/utils/tram_data_helpers.py:621\u001b[0m, in \u001b[0;36msample_continous_modelled_target.<locals>.f_vectorized\u001b[0;34m(targets)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf_vectorized\u001b[39m(targets):\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvectorized_object_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthetas_expanded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshifts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatent_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TramDag/utils/loss_continous.py:418\u001b[0m, in \u001b[0;36mvectorized_object_function\u001b[0;34m(thetas, targets, shifts, latent_sample, k_min, k_max)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvectorized_object_function\u001b[39m( thetas: torch\u001b[38;5;241m.\u001b[39mTensor,targets: torch\u001b[38;5;241m.\u001b[39mTensor, shifts: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    416\u001b[0m                                latent_sample: torch\u001b[38;5;241m.\u001b[39mTensor, k_min: \u001b[38;5;28mfloat\u001b[39m, k_max: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# h(xj)-latent_sample=0 , solve for xj\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh_extrapolated_with_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshifts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_max\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m latent_sample\n",
      "File \u001b[0;32m~/TramDag/utils/loss_continous.py:318\u001b[0m, in \u001b[0;36mh_extrapolated_with_shift\u001b[0;34m(thetas, targets, shifts, k_min, k_max)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# Left extrapolation\u001b[39;00m\n\u001b[1;32m    317\u001b[0m b0 \u001b[38;5;241m=\u001b[39m h_dag(L_tensor\u001b[38;5;241m.\u001b[39mexpand_as(targets), thetas)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m shifts_exp\n\u001b[0;32m--> 318\u001b[0m slope0 \u001b[38;5;241m=\u001b[39m \u001b[43mh_dag_dash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    319\u001b[0m h_left \u001b[38;5;241m=\u001b[39m slope0 \u001b[38;5;241m*\u001b[39m (t_i_exp \u001b[38;5;241m-\u001b[39m L_tensor) \u001b[38;5;241m+\u001b[39m b0\n\u001b[1;32m    321\u001b[0m h \u001b[38;5;241m=\u001b[39m h_left\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/TramDag/utils/loss_continous.py:172\u001b[0m, in \u001b[0;36mh_dag_dash\u001b[0;34m(targets, thetas)\u001b[0m\n\u001b[1;32m    170\u001b[0m _, b \u001b[38;5;241m=\u001b[39m thetas\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    171\u001b[0m dtheta \u001b[38;5;241m=\u001b[39m thetas[:, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m thetas[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]         \u001b[38;5;66;03m# shape (n, b-1)\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m B_dash \u001b[38;5;241m=\u001b[39m \u001b[43mbernstein_basis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# shape (n, b-1)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msum(B_dash \u001b[38;5;241m*\u001b[39m dtheta, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/TramDag/utils/loss_continous.py:140\u001b[0m, in \u001b[0;36mbernstein_basis\u001b[0;34m(tensor, M)\u001b[0m\n\u001b[1;32m    131\u001b[0m log_binomial_coeff \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    132\u001b[0m     torch\u001b[38;5;241m.\u001b[39mlgamma(M \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m    133\u001b[0m     \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mlgamma(k_values \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m    134\u001b[0m     \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mlgamma(M \u001b[38;5;241m-\u001b[39m k_values \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Log powers\u001b[39;00m\n\u001b[1;32m    138\u001b[0m log_powers \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    139\u001b[0m     k_values \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(tensor_expanded)\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;241m+\u001b[39m (M \u001b[38;5;241m-\u001b[39m k_values) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_expanded\u001b[49m)\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Bernstein basis in log space\u001b[39;00m\n\u001b[1;32m    144\u001b[0m log_bernstein \u001b[38;5;241m=\u001b[39m log_binomial_coeff \u001b[38;5;241m+\u001b[39m log_powers  \u001b[38;5;66;03m# shape (B, Nodes, M+1)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tramdag/lib/python3.9/site-packages/torch/_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tramdag/lib/python3.9/site-packages/torch/_tensor.py:1073\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m-> 1073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VariableFunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "td_model.sample(device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tramdag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
