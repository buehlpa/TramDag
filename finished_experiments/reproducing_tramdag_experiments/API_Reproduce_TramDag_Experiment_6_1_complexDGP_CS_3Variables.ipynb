{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.configuration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0363e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"API_tramdagpaper_exp6_1_complexDGP_cs\"      ## <--- set experiment name\n",
    "LOG_DIR=\"/home/bule/TramDag/dev_experiment_logs\"  ## <--- set log directory\n",
    "EXPERIMENT_DIR = os.path.join(LOG_DIR, experiment_name)\n",
    "CONF_DICT_PATH = os.path.join(EXPERIMENT_DIR, f\"configuration.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e17cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_configuration(experiment_name,EXPERIMENT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you need to specify which varibles are in the graph and what type they are (continous or ordinal) for the model builder \n",
    "data_type= {'x1':'continous',\n",
    "            'x2':'continous',\n",
    "            'x3':'continous'} \n",
    "\n",
    "write_data_type_to_configuration(data_type, CONF_DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_adj_matrix(CONF_DICT_PATH,seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee619cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_nn_names_matrix(CONF_DICT_PATH, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05947750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "from scipy.special import logit\n",
    "\n",
    "\n",
    "# 1. Linear-shift DGP and linear-shift model \n",
    "def f(x):\n",
    "    return 0.75*np.arctan(5*(x+0.12))  \n",
    "\n",
    "def dgp(n_obs, doX=[None, None, None], seed=-1):\n",
    "    if seed > 0:\n",
    "        np.random.seed(seed)\n",
    "        print(f\"Setting Seed: {seed}\")\n",
    "    \n",
    "    # Generate x1 from a 2-component GMM\n",
    "    \n",
    "    # h(x1)= SI \n",
    "    \n",
    "    \n",
    "    if doX[0] is None:\n",
    "        x1_A = np.random.normal(0.25, 0.1, n_obs)\n",
    "        x1_B = np.random.normal(0.73, 0.05, n_obs)\n",
    "        mix = np.random.choice([0, 1], size=n_obs)\n",
    "        x1 = np.where(mix == 0, x1_A, x1_B)\n",
    "    else:\n",
    "        x1 = np.full(n_obs, doX[0])\n",
    "\n",
    "\n",
    "\n",
    "    # Fz(z)=Fy(y)\n",
    "    # Fz(h(y|x))=Fy(y)    | z= h(y|x)\n",
    "\n",
    "    # Generate x2\n",
    "    \n",
    "    # h(x2|x1)= Bernsteinpol(x2) + beta2 * x1        | bernsteinpol is just linearized assumed with a constant factor say 0.42\n",
    "    # h(x2|x1)= 0.42*x2 + beta2 * x1                 | replace h(x2|x1) with z\n",
    "    # z       = 0.42*x2 + beta2 * x1                 | reformulate to x2\n",
    "    # x2      = (z-beta2 * x1 )/0.42                 | sample z from standart logistic via uniform and logit(np.random.uniform(size=n_obs))\n",
    "    # x2      = (z-beta2 * x1 )/0.42                 | set beta = 2 (on the edge of the graph)\n",
    "    # x2      = (z-2 * x1 )/0.42                     |\n",
    "    \n",
    "    if doX[1] is None:\n",
    "        u2 = np.random.uniform(size=n_obs)\n",
    "        z2 = logit(u2)\n",
    "        x2 = (z2 - 2 * x1) / 5#5#   0.42  in the trainagle strucutred cont last line is 5 for SI\n",
    "    else:\n",
    "        x2 = np.full(n_obs, doX[1])\n",
    "\n",
    "    # Generate x3\n",
    "    \n",
    "    # h(x3|x2,x1)= Bernsteinpol(x3) + beta3 * x1 -f(X2)        | bernsteinpol is just linearized assumed with a constant factor say 0.63\n",
    "    # h(x3|x2,x1)= 0.63*x3 + beta3 * x1          - f(X2)        | replace h(x2|x1) with z\n",
    "    # z3          = 0.63*x3 + beta3 * x1          - f(X2)        | reformulate to x2\n",
    "    # x3         = (z3-beta3 * x1 +f(X2))/0.63                   | sample z from standart logistic via uniform and logit(np.random.uniform(size=n_obs))\n",
    "    # x3         = (z3-beta3 * x1 +f(X2))/0.63                   | set beta = -0.2 (on the edge of the graph)\n",
    "    # x3         = (z3+0.2 * x1   +f(X2))/0.63                   | \n",
    "\n",
    "    \n",
    "    if doX[2] is None:\n",
    "        u3 = np.random.uniform(size=n_obs)\n",
    "        z3 = logit(u3)\n",
    "        x3 = (z3 + 0.2 * x1 + f(x2)) / 0.63\n",
    "    else:\n",
    "        x3 = np.full(n_obs, doX[2])\n",
    "        \n",
    "    #df = pd.DataFrame({'x1': x1, 'x2': x2})#, 'x3': x3})\n",
    "    df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3})\n",
    "    return df\n",
    "\n",
    "n_obs=100_000\n",
    "\n",
    "df = dgp(n_obs=n_obs, seed=42)\n",
    "\n",
    "# 1. Split the data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tramdag import TramDagConfig , TramDagModel\n",
    "\n",
    "cfg = TramDagConfig.load(\"/home/bule/TramDag/dev_experiment_logs/API_tramdagpaper_exp6_1_complexDGP_cs/configuration.json\")\n",
    "cfg.plot_dag()\n",
    "\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_model = TramDagModel.from_config(cfg, set_initial_weights=False,verbose=True,debug=True,device=device,initial_data = train_df) \n",
    "# 1m52s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12779127",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_model.fit(train_df, val_df,\n",
    "             epochs=260,batch_size=1_000,\n",
    "             verbose=True,debug=False,\n",
    "             device=device,\n",
    "             num_workers = 8,\n",
    "             persistent_workers = True,\n",
    "             prefetch_factor = 8,\n",
    "             train_mode = \"parallel\")#,\n",
    "\n",
    "#30 eps 1m 49s seq mode from start 1000 bs\n",
    "#30 eps 2m 27s parllel multiprocessing mode from start 1000 bs\n",
    "# 200 eps 9m 30s seq mode from start 1000 bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cabc55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents=td_model.get_latent( train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, latents = td_model.sample(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, latents = td_model.sample(predefined_latent_samples_df=latents, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06bfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_model.show_samples_vs_true(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tramdag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
